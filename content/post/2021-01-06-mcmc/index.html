---
title: MCMC
author: dondon
date: '2021-01-06'
slug: mcmc
categories:
  - R
tags:
  - statistics
---



<div id="markov-chain-monte-carlomcmc" class="section level1">
<h1>Markov Chain Monte Carlo(MCMC)</h1>
<p>켤레 사전 분포처럼 분포함수 간에 관계가 있거나 함수가 간단한 형태의 경우 적분을 쉽게 할 수 있다. 하지만 복잡한 함수 형태이거나 high dimension인 경우 Monte carlo integration이나 numerical method를 이용한 적분 방법을 적용하기 힘들다. 이 때 사용하는 방법이 Markov chain Monte Carlo 방법이다.</p>
<p>Monte Carlo integration의 경우 independence sample을 뽑는데 high dimension인 경우 independence sample을 뽑는 것이 어렵다. 따라서 dependence sample을 뽑아서 이 문제를 해결해보자는 것이 Markov Chain Monte Carlo(MCMC)의 아이디어이다. 앞에 Markov Chain이 붙은 것은 dependence sample을 Markov Chain 구조에서 뽑기 때문이다. 이상적인 Markov Chain의 경우 특정 정칙 조건을 만족해야한다.</p>
<div id="regularity-conditions" class="section level2">
<h2>regularity conditions</h2>
<ul>
<li>irreducibility</li>
<li>positive recurrence</li>
<li>aperiodicity</li>
</ul>
<p><br><br></p>
</div>
</div>
<div id="metopolis-hasting-algorithm" class="section level1">
<h1>Metopolis-Hasting algorithm</h1>
<p>Markov Chain을 따르는 <span class="math inline">\(X\)</span>를 발생시키기 위해서는 regularity conditions을 만족해야 한다.
<strong>일반적으로 target distribution과 같은 support set을 갖는 proposal distribution의 경우 regularity conditions를 만족한다.</strong>
proposal distribution이 regularity condition을 만족하는 경우 Metropolis-Hastings chain의 stationary distribution은 taget distribution이 된다.</p>
<ol style="list-style-type: decimal">
<li>target distribution과 support set이 같은 임의의 proposal distribution <span class="math inline">\(g(\cdot|X_t)\)</span>를 선정한다.<br />
</li>
<li><span class="math inline">\(g(\cdot|X_t)\)</span>에서 초기값 <span class="math inline">\(X_0\)</span>를 생성한다.</li>
<li>chain이 정상 분포로 수렴할 때까지 다음의 과정을 반복한다.</li>
</ol>
<ul>
<li><span class="math inline">\(g(\cdot|X_t)\)</span>로부터 <span class="math inline">\(Y\)</span>를 발생시킨다.</li>
<li><span class="math inline">\(U(0,1)\)</span>에서 random number <span class="math inline">\(U\)</span>를 발생시킨다.</li>
<li>If <span class="math inline">\(U\le r(X_t, Y) = \frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}\)</span> <span class="math inline">\(Y\)</span>를 채택, <span class="math inline">\(X_{t+1}=Y\)</span>
otherwise <span class="math inline">\(X_{t+1}=X_t\)</span></li>
<li>Increment t</li>
</ul>
<div id="example" class="section level2">
<h2>example</h2>
<p>Metropolis-Hasting algorithm을 이용해서 Rayleigh 분포에서 표본을 추출하기 해보자.</p>
<p><span class="math inline">\(f(x) = \frac{x}{\sigma^2}e^\frac{-x^2}{2\sigma^2}\)</span>, <span class="math inline">\(x\ge0\)</span>, <span class="math inline">\(\sigma&gt;0\)</span></p>
<ol style="list-style-type: decimal">
<li>target distribution과 support set이 같은 임의의 proposal distribution로 <span class="math inline">\(\mathcal{X}^2(X)\)</span>를 선정한다.<br />
</li>
<li><span class="math inline">\(\mathcal{X}^2(1)\)</span>에서 초기값 <span class="math inline">\(X_0\)</span>를 생성하고 x[1]에 저장한다.<br />
</li>
<li><span class="math inline">\(i=2,...,N\)</span>까지 반복한다.</li>
</ol>
<ul>
<li><span class="math inline">\(\mathcal{X}^2(df = X_t)=\mathcal{X}^2(df = X[i-1])\)</span>로부터 <span class="math inline">\(Y\)</span>를 발생시킨다.</li>
<li><span class="math inline">\(U(0,1)\)</span>에서 random number <span class="math inline">\(U\)</span>를 발생시킨다.</li>
<li><span class="math inline">\(X_t\)</span>=x[i-1],
If <span class="math inline">\(U\le \frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}\)</span> <span class="math inline">\(Y\)</span>를 채택, <span class="math inline">\(X_{t+1}=Y\)</span>
otherwise <span class="math inline">\(X_{t+1}=X_t\)</span>
<span class="math inline">\(X_t+1\)</span>을 x[i]에 저장한다.</li>
<li>Increment t</li>
</ul>
<p><span class="math inline">\(Y\)</span>가 accept 될 확률은 다음과 같다.
<span class="math inline">\(\alpha (X_t, Y) = min(1, \frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)})\)</span></p>
<pre class="r"><code>rayleigh &lt;- function(x, sigma){
        return ((x/sigma^2)*exp(-x^2/(2*sigma^2))) # Rayleigh distribution를 함수로 정의
}

m &lt;- 10000
sigma &lt;- 4
x &lt;- numeric(m)
x[1] &lt;- rchisq(1, df = 1) # initial value 
k &lt;- 0 
u &lt;- runif(m) # generate u from U(0,1)

for (i in 2:m) {
        xt &lt;- x[i-1]
        y &lt;- rchisq(1, df = xt)
        num &lt;- rayleigh(y, sigma)*dchisq(xt, df = y) # posterior theta t
        den &lt;- rayleigh(xt, sigma)*dchisq(y, df = xt) # posterior theta t-1
        
        if (u[i] &lt;= num/den) {
                x[i] &lt;- y # accept 
        }else {
                x[i] &lt;- xt # reject 
                k &lt;- k+1
        }
}
k # reject된 갯수 </code></pre>
<pre><code>## [1] 4126</code></pre>
<p><br><br></p>
<p>실제 Rayleigh 분포와 같은지를 비교하기 위해 QQplot을 그리면 다음과 같다.</p>
<pre class="r"><code>b &lt;- 2001
y &lt;- x[b:m]
a &lt;- ppoints(100)
QR &lt;- sigma*sqrt(-2*log(1-a))
Q &lt;- quantile(y, a)

qqplot(QR, Q, main = &#39;&#39;, cex = 0.5, xlab = &#39;Rayleigh Quantiles&#39;, ylab = &#39;Sample Quantiles&#39;)
abline(0,1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" width="672" />
<br><br></p>
<p>proposal distribution을 gamma distribution으로 변경할 경우 다음과 같다.</p>
</div>
</div>
<div id="metropolis-sampler" class="section level1">
<h1>Metropolis Sampler</h1>
<p>Matropolis Hastings sampler는 Metropolis sampler의 일반화이다.
Metropolis sampler는 Metropolis algorithm에서 proposal distribution이 symmetric일 때를 의미한다.</p>
<p>proposal distribution이 symmetric이므로</p>
<p><span class="math inline">\(g(X|Y) = g(Y|X)\)</span></p>
<p>를 만족한다.</p>
<p>따라서 기존의 Metropolis Hastings sampler 식은 조건부 분포 <span class="math inline">\(g\)</span>가 약분되므로 식이 간소화된다.
<span class="math inline">\(r(X_t, Y) = \frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)} = \frac{f(Y)}{f(X_t)}\)</span></p>
<p><br><br></p>
</div>
<div id="random-walk-metropolis" class="section level1">
<h1>Random Walk Metropolis</h1>
<p>Random Walk Metropolis sampler는 Metropolis Sampler의 special case이다.
proposal distribution은 symmetric이며, <span class="math inline">\(g(Y|X_t) = g(X_t - Y)\)</span>로 정의한다.</p>
<ol style="list-style-type: decimal">
<li><p>random increment <span class="math inline">\(Z\)</span>를 <span class="math inline">\(g(\cdot)\)</span>로 부터 발생시킨다.</p></li>
<li><p><span class="math inline">\(Y=X_t+Z\)</span> 로 정의한다.</p></li>
<li><p><span class="math inline">\(r(X_t, Y) = \frac{f(Y)}{f(X_t)}\)</span>를 계산한다.</p></li>
<li><p>target distribution과 support set이 같은 임의의 proposal distribution <span class="math inline">\(g(\cdot|X_t)\)</span>를 선정한다. proposal distribution은 symmetric이며, <span class="math inline">\(g(Y|X_t) = g(X_t - Y)\)</span>로 정의한다.</p></li>
<li><p>random increment <span class="math inline">\(Z\)</span>를 <span class="math inline">\(g(\cdot)\)</span>로 부터 발생시키고, <span class="math inline">\(Y=X_t+Z\)</span> 로 정의한다.</p></li>
<li><p>chain이 정상 분포로 수렴할 때까지 다음의 과정을 반복한다.</p></li>
</ol>
<ul>
<li><span class="math inline">\(r(X_t, Y) = \frac{f(Y)}{f(X_t)}\)</span>를 계산한다.</li>
<li><span class="math inline">\(U(0,1)\)</span>에서 random number <span class="math inline">\(U\)</span>를 발생시킨다.</li>
<li>If <span class="math inline">\(U\le r(X_t, Y) = \frac{f(Y)g(X_t|Y)}{f(X_t)g(Y|X_t)}\)</span> <span class="math inline">\(Y\)</span>를 채택, <span class="math inline">\(X_{t+1}=Y\)</span>
otherwise <span class="math inline">\(X_{t+1}=X_t\)</span></li>
<li>Increment t</li>
</ul>
<p><br><br></p>
</div>
<div id="independence-sampler" class="section level1">
<h1>independence sampler</h1>
<p>independence sampler는 Metropolis Hastings Sampler의 special case이다.
independence sampler에서 proposal distribution은 다음과 같이 정의된다.</p>
<p><span class="math inline">\(g(Y|X_t) = g(Y)\)</span></p>
<p>즉, independence sampler는 chain의 이전 값에 의존하지 않는다.</p>
<p>independence sampler는 proposal density가 target density에 가깝게 match될 경우에 잘 동작한다. 하지만 이러한 경우는 거의 없으며, independence sampler는 잘 동작하지 않는 경우가 많다. 따라서 단독으로 쓰이는 경우는 없으며, 보통 hybrid MCMC method에서 사용한다.</p>
<p><br><br></p>
</div>
<div id="gibbs-sampler" class="section level1">
<h1>Gibbs sampler</h1>
<p>Gibbs sampler도 Metropolis Hastings Sampler의 special case이다. target distribution이 multivariate distribution일 때 주로 적용한다.
Gibbs sampler는 일변량 조건부 분포를 계산할 수 있고, 쉽게 simulation이 가능한 경우에 사용할 수 있다.</p>
<p><span class="math inline">\(X_{(-j)} = (X_1, ... , X_{j-1}, X_{j+1}, ... , X_d)\)</span></p>
<p><span class="math inline">\(f(x_1, x_2, ..., x_k)\)</span> : joint pdf를 계산하기 어려움
<span class="math inline">\(f(x_1) = \int f(x_1, x_2, ..., x_k)\, dx_2...dx_d\)</span> : marginal pdf를 계산하기 어려움
<span class="math inline">\(f(x_1|x_2,...,x_d)\)</span> : conditional pdf는 구하기 쉬움</p>
<p>간단하게 multivariate distribution일 때를 예로 들면</p>
<p><span class="math inline">\(f(x, y)\)</span> : joint pdf를 계산하기 어려움
<span class="math inline">\(f(x) = \int f(x,y)\, dy\)</span> : marginal pdf를 계산하기 어려움
<span class="math inline">\(f(y) = \int f(x,y)\, dx\)</span>
<span class="math inline">\(f(x|y)\)</span>, <span class="math inline">\(f(y|x)\)</span> : conditional pdf는 구하기 쉬움</p>
<p>Gibbs sampler를 직관적으로 설명하면</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(y\)</span>가 주어졌을 때 <span class="math inline">\(f(x|y)\)</span>로 부터 구한 <span class="math inline">\(x\)</span>값을 <span class="math inline">\(f(y|x)\)</span>의 given <span class="math inline">\(x\)</span>값으로 집어넣는다.</li>
<li><span class="math inline">\(f(y|x)\)</span>에서 나온 <span class="math inline">\(y\)</span>값을 <span class="math inline">\(f(x|y)\)</span>의 given <span class="math inline">\(y\)</span> 값으로 집어넣는다.</li>
<li>이러한 과정을 계속 반복해서 <span class="math inline">\((X_1, Y_1, ....)\)</span>를 구한다.</li>
<li><span class="math inline">\((X_1, Y_1, ....|X_i, Y_i......)\)</span>의 일정 부분을 burn out하고 <span class="math inline">\((X_i, Y_i......)\)</span>만 남긴다.</li>
<li><span class="math inline">\((X_i, Y_i......)\)</span>는 <span class="math inline">\(f(x,y)\)</span>에서 뽑은 sample이 된다.</li>
</ol>
<p>즉, Gibbs sampler의 핵심은 conditinal pdf로부터 joint pdf or marginal pdf를 쉽게 계산할 수 있다는 것이다. 핵심이다.</p>
<p><br></p>
<div id="gibbs-sampler-algorithm" class="section level3">
<h3>Gibbs sampler algorithm</h3>
<p><span class="math inline">\(X_{(-j)} = (X_1, ... , X_{j-1}, X_{j+1}, ... , X_d)\)</span></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(t=0\)</span> 시점에서의 초기값 <span class="math inline">\(X(0)\)</span>를 생성한다.</li>
<li><span class="math inline">\(t=1, 2, ...\)</span> 에 대해 다음을 반복한다.</li>
</ol>
<ul>
<li><span class="math inline">\(x_1=X_1(t-1)\)</span>을 구한다.</li>
<li>각 <span class="math inline">\(j = 1, 2,...,d\)</span>에 대해</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(f(X_j|x_{(-j)})\)</span>로 부터 <span class="math inline">\(X_j^*(t)\)</span>를 발생시킨다.</li>
<li><span class="math inline">\(x_j=X_j^*(t)\)</span>를 update한다.</li>
</ol>
<ul>
<li><span class="math inline">\(X(t)=(X_1^*(t), ... , X_d^*(t)\)</span>를 구한다.</li>
<li>Increment t</li>
</ul>
</div>
<div id="example-beta-binomial-distribution" class="section level3">
<h3>example (beta-binomial distribution)</h3>
<p><span class="math inline">\(f(x,y) = {n \choose x}y^{x+a-1}(1-y)^{n-x+b-1}\)</span>, <span class="math inline">\(x=0,1,....,n\)</span>, <span class="math inline">\(0 \le y \le 1\)</span>
<span class="math inline">\(X|y \sim Bin(n, y)\)</span>, <span class="math inline">\(Y|x \sim Beta(x+\alpha, n-x+\beta)\)</span></p>
<p>Gibbs sampling의 목적은 conditional pdf로 모르는 형태의 joint pdf와 marginal pdf를 구하는 것이다.
따라서 <span class="math inline">\(f(x,y)\)</span>는 실제로는 beta-binomial 분포로 구할 수 있지만 gibbs sampling을 위해서 <span class="math inline">\(f(x,y)\)</span>를 모르고 <span class="math inline">\(f(x|y)\)</span>와 <span class="math inline">\(f(y|x)\)</span>는 안다고 가정한다.</p>
</div>
<div id="algorithm" class="section level3">
<h3>algorithm</h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Bin(n, p = Y(t-1))\)</span>로부터 <span class="math inline">\(X^*(t)\)</span>를 발생시킨다.</li>
<li><span class="math inline">\(x(t) = X^*(t)\)</span>를 update한다.</li>
<li><span class="math inline">\(Beta(x(t)+\alpha, n-x(t)+\beta)\)</span>로부터 <span class="math inline">\(Y^*(t)\)</span>를 발생시킨다.</li>
<li>Set <span class="math inline">\((X(t), Y(t)) = (X^*(t), Y^*(t))\)</span>.</li>
</ol>
<p>추가적으로 <span class="math inline">\((X^*(t), Y^*(t))\)</span>에 대해서 일정량을 burn in 하는데 이는 초기값의 영향을 없애기 위해서이다. burn in의 비율은 임의로 설정한다.</p>
<p><br></p>
<pre class="r"><code>N &lt;- 500               
burn &lt;- 100            
n &lt;- 16
alpha &lt;- 2
beta &lt;- 4
x &lt;- rep(0, N)
y &lt;- rep(0, N)


x[1] &lt;- rbinom(1, prob = 0.5, size = n)
y[1] &lt;- rbeta(1, x[1]+alpha, n-x[1]+beta)

for (i in 2:N) {
        x[i] &lt;- rbinom(1, prob = y[i-1], size = n)
        y[i] &lt;- rbeta(1, x[i]+alpha, n-x[i]+beta)
}

burn_x &lt;- x[(burn+1):N]</code></pre>
</div>
<div id="example-bivariate-distribution" class="section level3">
<h3>example (Bivariate distribution)</h3>
<pre class="r"><code>N &lt;- 5000               
burn &lt;- 1000            
X &lt;- matrix(0, N, 2)    

rho &lt;- -.75             
mu1 &lt;- 0
mu2 &lt;- 2
sigma1 &lt;- 1
sigma2 &lt;- .5
s1 &lt;- sqrt(1-rho^2)*sigma1
s2 &lt;- sqrt(1-rho^2)*sigma2


X[1, ] &lt;- c(mu1, mu2) # 초기값

for (i in 2:N) {
        x2 &lt;- X[i-1, 2] # x2가 주어짐
        m1 &lt;- mu1 + rho * (x2 - mu2) * sigma1/sigma2 # x2가 주어졌을 때 x1 조건부 분포의 평균 
        X[i, 1] &lt;- rnorm(1, m1, s1) # 조건부 분포로 생성된 x1 업데이트 
        x1 &lt;- X[i, 1]
        m2 &lt;- mu2 + rho * (x1 - mu1) * sigma2/sigma1 # x1이 주어졌을 때 x2 조건부 분포의 평균
        X[i, 2] &lt;- rnorm(1, m2, s2) # 조건부 분포로 생성된 x1 업데이트
}

b &lt;- burn + 1 # 임의로 부여한 initial value의 효과를 없앰. 
x &lt;- X[b:N, ] # 1000개 버림

colMeans(x) # 0, 2에 거의 근사 </code></pre>
<pre><code>## [1] -0.02010863  2.01351264</code></pre>
<pre class="r"><code>cov(x)</code></pre>
<pre><code>##            [,1]       [,2]
## [1,]  0.9383263 -0.3451543
## [2,] -0.3451543  0.2390855</code></pre>
<pre class="r"><code>cor(x) # rho = -0.75에 거의 근사 </code></pre>
<pre><code>##            [,1]       [,2]
## [1,]  1.0000000 -0.7287183
## [2,] -0.7287183  1.0000000</code></pre>
<pre class="r"><code>plot(x, main = &#39;&#39;, cex = 0.5, xlab = bquote(X[1]), ylab = bquote(X[2]), ylim = range(x[, 2]))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
</div>
