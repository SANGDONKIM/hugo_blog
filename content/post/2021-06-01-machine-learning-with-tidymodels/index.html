---
title: 'Machine learning with tidymodels '
author: "dondon"
date: '2021-06-01'
slug: machine-learning-with-tidymodels
categories: statistics
tags: Machine learning
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="machine-learning-tutorial" class="section level1">
<h1>Machine learning tutorial</h1>
<p>adp 시험을 대비해서 대표적인 machine learning 모델 몇 가지를 골라서 tutorial 자료를 만들고자 한다. tidymodels 의 workflow는 패키지가 달라도 항상 동일하기 때문에 튜닝 파라미터를 제외하면 달라지는건 없는 것 같다. 시험이 3일 남았지만 이번 기회에 한번 정리를 해본다(ADP 관련 내용은 관련 후기 글을 보고 비슷하게 따라해본 내용이므로 참고만 하는 것이 좋다).</p>
<div id="packages" class="section level2">
<h2>packages</h2>
</div>
</div>
<div id="시계열-온도-예측-모델" class="section level1">
<h1>1. 시계열 온도 예측 모델</h1>
<ul>
<li><p>데이터 전처리 : 결측값 처리, 필요없는 칼럼 삭제, 데이터 전처리가 되었다는 증명, train/test 분리</p></li>
<li><p>Random forest 모델 적합</p></li>
<li><p>Random forest 예측 한계선을 설정하는 방법을 말하고 어떤 방법을 써야하는지 설명</p></li>
<li><p>Random forest를 활용해 예측 및 검증, 파라미터 튜닝</p></li>
<li><p>변수 중요도 시각화</p></li>
<li><p>svm을 이용해 예측 및 검증, 파라미터 튜닝</p></li>
<li><p>변수 중요도 시각화</p></li>
<li><p>svm과 rf 장·단점 설명하기</p></li>
<li><p>두 모델 중에 어떤 모델이 좋은지 선택하고 설명하기</p></li>
<li><p>선택한 모델의 한계점을 설명하고 한계점을 해결할 방법 설명하기</p></li>
</ul>
<div id="data-description" class="section level2">
<h2>Data description</h2>
<ul>
<li>temp_2 : 2일 전 최대 온도</li>
<li>temp_1 : 1일 전 최대 온도</li>
<li>average : 과거 평균 최대 온도</li>
<li>actual : 실제 최대 온도</li>
<li>friend : 친구의 예측값, random number</li>
<li>기타 등등..</li>
</ul>
</div>
<div id="data-preprocessing" class="section level2">
<h2>Data preprocessing</h2>
<div id="데이터-불러오기" class="section level3">
<h3>데이터 불러오기</h3>
<pre class="r"><code>dat &lt;- fread(&#39;temps.csv&#39;)
head(dat)</code></pre>
<pre><code>##    year month day week temp_2 temp_1 average actual forecast_noaa forecast_acc
## 1: 2016     1   1  Fri     45     45    45.6     45            43           50
## 2: 2016     1   2  Sat     44     45    45.7     44            41           50
## 3: 2016     1   3  Sun     45     44    45.8     41            43           46
## 4: 2016     1   4  Mon     44     41    45.9     40            44           48
## 5: 2016     1   5 Tues     41     40    46.0     44            46           46
## 6: 2016     1   6  Wed     40     44    46.1     51            43           49
##    forecast_under friend
## 1:             44     29
## 2:             44     61
## 3:             47     56
## 4:             46     53
## 5:             46     41
## 6:             48     40</code></pre>
</div>
<div id="변수-속성-확인" class="section level3">
<h3>변수 속성 확인</h3>
<p>날짜 변수의 속성이 integer이므로 변환이 필요해보인다.</p>
<pre class="r"><code>glimpse(dat)</code></pre>
<pre><code>## Rows: 348
## Columns: 12
## $ year           &lt;int&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2~
## $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~
## $ day            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, ~
## $ week           &lt;chr&gt; &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;, &quot;Mon&quot;, &quot;Tues&quot;, &quot;Wed&quot;, &quot;Thurs&quot;, &quot;Fr~
## $ temp_2         &lt;int&gt; 45, 44, 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49,~
## $ temp_1         &lt;int&gt; 45, 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49, 55,~
## $ average        &lt;dbl&gt; 45.6, 45.7, 45.8, 45.9, 46.0, 46.1, 46.2, 46.3, 46.4, 4~
## $ actual         &lt;int&gt; 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49, 55, 49,~
## $ forecast_noaa  &lt;int&gt; 43, 41, 43, 44, 46, 43, 45, 43, 46, 45, 42, 44, 45, 43,~
## $ forecast_acc   &lt;int&gt; 50, 50, 46, 48, 46, 49, 49, 47, 50, 48, 48, 50, 51, 47,~
## $ forecast_under &lt;int&gt; 44, 44, 47, 46, 46, 48, 46, 46, 45, 48, 48, 45, 46, 46,~
## $ friend         &lt;int&gt; 29, 61, 56, 53, 41, 40, 38, 34, 47, 49, 39, 61, 33, 58,~</code></pre>
</div>
<div id="변수-삭제-날짜-변수-처리" class="section level3">
<h3>변수 삭제, 날짜 변수 처리</h3>
<p>year, month, day를 하나로 묶어서 date라는 파생변수를 만들었다. 파생 변수를 만들지 않고, 날짜 변수 각각을 lubridate로 처리하려고 하면 골치아프다. 파생변수 date를 이용해서 date를 다시 만들고, year 변수의 경우 2016년만 있기 때문에 제외했다. week 변수의 경우 factor로 변경했다.</p>
<pre class="r"><code>dat %&gt;% select(-starts_with(&#39;forecast_&#39;), -friend) %&gt;% 
                mutate(date = paste0(year, &#39;-&#39;, month, &#39;-&#39;, day)) %&gt;% 
                select(-c(year, month, day, week)) %&gt;% 
                mutate(date = ymd(date), 
                       year = year(date), 
                       month = month(date), 
                       day = day(date), 
                       week = weekdays(date)) %&gt;% 
                select(-c(date, year)) %&gt;% 
                select(month, week, day, everything()) %&gt;% 
                mutate(week = as.factor(week)) -&gt; dat
                
glimpse(dat)                </code></pre>
<pre><code>## Rows: 348
## Columns: 7
## $ month   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~
## $ week    &lt;fct&gt; 금요일, 토요일, 일요일, 월요일, 화요일, 수요일, 목요일, 금요일~
## $ day     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,~
## $ temp_2  &lt;int&gt; 45, 44, 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49, 55, 49~
## $ temp_1  &lt;int&gt; 45, 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49, 55, 49, 48~
## $ average &lt;dbl&gt; 45.6, 45.7, 45.8, 45.9, 46.0, 46.1, 46.2, 46.3, 46.4, 46.5, 46~
## $ actual  &lt;int&gt; 45, 44, 41, 40, 44, 51, 45, 48, 50, 52, 45, 49, 55, 49, 48, 54~</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##      month            week         day            temp_2           temp_1     
##  Min.   : 1.000   금요일:50   Min.   : 1.00   Min.   : 35.00   Min.   : 35.0  
##  1st Qu.: 3.000   목요일:49   1st Qu.: 8.00   1st Qu.: 54.00   1st Qu.: 54.0  
##  Median : 6.000   수요일:49   Median :15.00   Median : 62.50   Median : 62.5  
##  Mean   : 6.477   월요일:49   Mean   :15.51   Mean   : 62.65   Mean   : 62.7  
##  3rd Qu.:10.000   일요일:49   3rd Qu.:23.00   3rd Qu.: 71.00   3rd Qu.: 71.0  
##  Max.   :12.000   토요일:50   Max.   :31.00   Max.   :117.00   Max.   :117.0  
##                   화요일:52                                                   
##     average          actual     
##  Min.   :45.10   Min.   :35.00  
##  1st Qu.:49.98   1st Qu.:54.00  
##  Median :58.20   Median :62.50  
##  Mean   :59.76   Mean   :62.54  
##  3rd Qu.:69.03   3rd Qu.:71.00  
##  Max.   :77.40   Max.   :92.00  
## </code></pre>
</div>
<div id="결측치-확인" class="section level3">
<h3>결측치 확인</h3>
<p>n_missing을 보면 결측치는 존재하지 않는 것으로 확인된다.</p>
<pre class="r"><code>skimr::skim(dat)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">dat</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">348</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left">Key</td>
<td align="left">NULL</td>
</tr>
<tr class="odd">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">6</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">week</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">7</td>
<td align="left">화요일: 52, 금요일: 50, 토요일: 50, 목요일: 49</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">month</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.48</td>
<td align="right">3.50</td>
<td align="right">1.0</td>
<td align="right">3.00</td>
<td align="right">6.0</td>
<td align="right">10.00</td>
<td align="right">12.0</td>
<td align="left">▇▆▆▅▇</td>
</tr>
<tr class="even">
<td align="left">day</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">15.51</td>
<td align="right">8.77</td>
<td align="right">1.0</td>
<td align="right">8.00</td>
<td align="right">15.0</td>
<td align="right">23.00</td>
<td align="right">31.0</td>
<td align="left">▇▇▆▆▆</td>
</tr>
<tr class="odd">
<td align="left">temp_2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">62.65</td>
<td align="right">12.17</td>
<td align="right">35.0</td>
<td align="right">54.00</td>
<td align="right">62.5</td>
<td align="right">71.00</td>
<td align="right">117.0</td>
<td align="left">▃▇▆▁▁</td>
</tr>
<tr class="even">
<td align="left">temp_1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">62.70</td>
<td align="right">12.12</td>
<td align="right">35.0</td>
<td align="right">54.00</td>
<td align="right">62.5</td>
<td align="right">71.00</td>
<td align="right">117.0</td>
<td align="left">▃▇▆▁▁</td>
</tr>
<tr class="odd">
<td align="left">average</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">59.76</td>
<td align="right">10.53</td>
<td align="right">45.1</td>
<td align="right">49.98</td>
<td align="right">58.2</td>
<td align="right">69.03</td>
<td align="right">77.4</td>
<td align="left">▇▅▃▅▆</td>
</tr>
<tr class="even">
<td align="left">actual</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">62.54</td>
<td align="right">11.79</td>
<td align="right">35.0</td>
<td align="right">54.00</td>
<td align="right">62.5</td>
<td align="right">71.00</td>
<td align="right">92.0</td>
<td align="left">▂▆▇▅▂</td>
</tr>
</tbody>
</table>
<pre class="r"><code>dat %&gt;% is.na() %&gt;% colSums()</code></pre>
<pre><code>##   month    week     day  temp_2  temp_1 average  actual 
##       0       0       0       0       0       0       0</code></pre>
</div>
<div id="traintest-split" class="section level3">
<h3>train/test split</h3>
<p>train/test를 7:3 비율로 나눠주었다.</p>
<pre class="r"><code>set.seed(123)
splits &lt;- initial_split(dat, prop = 0.7, strata = actual)
train &lt;- training(splits)
test &lt;- testing(splits)</code></pre>
</div>
</div>
<div id="random-forest-model-fitting" class="section level2">
<h2>Random forest Model fitting</h2>
<div id="recipe" class="section level3">
<h3>Recipe</h3>
<p>week 변수를 one-hot encoding 으로 변환해주었다.</p>
<pre class="r"><code>model_rec &lt;- train %&gt;% recipe(actual~.) %&gt;% 
                step_dummy(week, one_hot = T) 

train2 &lt;- model_rec %&gt;% prep() %&gt;% juice()
test2 &lt;- model_rec %&gt;% prep() %&gt;% bake(new_data = test)</code></pre>
</div>
<div id="create-cv" class="section level3">
<h3>create cv</h3>
<p>모델 평가를 위해서 validation set을 생성해주었다.</p>
<pre class="r"><code>set.seed(123)
vb_folds &lt;- vfold_cv(train2, v = 3, strata = actual)</code></pre>
</div>
<div id="model-fitting" class="section level3">
<h3>Model fitting</h3>
<p>random forest를 적합시키고 파라미터 튜닝을 실시했다.</p>
<pre class="r"><code>rf_spec &lt;- rand_forest(
                mtry = tune(), 
                trees = 100) %&gt;% 
                set_mode(&#39;regression&#39;) %&gt;% 
                set_engine(&#39;ranger&#39;)

rf_wf &lt;- workflow() %&gt;% 
                add_formula(actual~.) %&gt;% 
                add_model(rf_spec)

library(tictoc)
tic()


set.seed(1234)
rf_res &lt;- tune_grid(
    rf_wf,  
    resamples = vb_folds, 
    grid = 30,
    metrics = metric_set(rmse), 
    control = control_grid(save_pred = T)  
)</code></pre>
<pre><code>## i Creating pre-processing data to finalize unknown parameter: mtry</code></pre>
<pre class="r"><code>toc() # 10.5 sec</code></pre>
<pre><code>## 10.09 sec elapsed</code></pre>
<pre class="r"><code>best_param_rf &lt;- select_best(rf_res) 
final_rf &lt;- finalize_workflow(rf_wf, best_param_rf)
final_rf</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Formula
## Model: rand_forest()
## 
## -- Preprocessor ----------------------------------------------------------------
## actual ~ .
## 
## -- Model -----------------------------------------------------------------------
## Random Forest Model Specification (regression)
## 
## Main Arguments:
##   mtry = 4
##   trees = 100
## 
## Computational engine: ranger</code></pre>
</div>
<div id="model-performance-check" class="section level3">
<h3>Model performance check</h3>
<p>모델 성능을 확인해보았다.</p>
<pre class="r"><code>final_rf_model &lt;- finalize_model(rf_spec, best_param_rf) 
final_rf_workflow &lt;- rf_wf %&gt;% update_model(final_rf_model)
rf_fit &lt;- fit(final_rf_workflow, data = train2)

pred &lt;- predict(rf_fit, test2 %&gt;% select(-actual))
actual &lt;- test2$actual

results &lt;- tibble(pred, actual)

metrics(results, truth = actual, estimate = .pred)</code></pre>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       4.94 
## 2 rsq     standard       0.828
## 3 mae     standard       3.84</code></pre>
</div>
<div id="feature-importance-plot" class="section level3">
<h3>Feature importance plot</h3>
<pre class="r"><code>library(vip)</code></pre>
<pre><code>## 
## 다음의 패키지를 부착합니다: &#39;vip&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     vi</code></pre>
<pre class="r"><code>imp_spec &lt;- rf_spec %&gt;%
  finalize_model(best_param_rf) %&gt;%
  set_engine(&quot;ranger&quot;, importance = &quot;permutation&quot;)

workflow() %&gt;%
  add_recipe(model_rec) %&gt;%
  add_model(imp_spec) %&gt;%
  fit(train) %&gt;%
  pull_workflow_fit() %&gt;%
  vip(aesthetics = list(alpha = 0.8, fill = &quot;midnightblue&quot;))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
</div>
<div id="svm-model-fitting" class="section level2">
<h2>SVM Model fitting</h2>
<p>SVM 모델을 적합하고 파라미터 튜닝을 실시했다.</p>
<div id="model-fitting-1" class="section level3">
<h3>Model fitting</h3>
<pre class="r"><code>svm_spec &lt;- svm_poly(cost = tune(), degree = 1) %&gt;% 
    set_engine(&#39;kernlab&#39;) %&gt;% 
    set_mode(&#39;regression&#39;)

svm_wf &lt;- workflow() %&gt;% 
                add_formula(actual~.) %&gt;% 
                add_model(svm_spec)

library(tictoc)
tic()

set.seed(1234)
svm_res &lt;- tune_grid(
    svm_wf,  
    resamples = vb_folds, 
    grid = 30,
    metrics = metric_set(rmse), 
    control = control_grid(save_pred = T)  
)
toc() # 10.5 sec</code></pre>
<pre><code>## 25.64 sec elapsed</code></pre>
<pre class="r"><code>best_param_svm &lt;- select_best(svm_res) 
final_svm &lt;- finalize_workflow(svm_wf, best_param_svm)
final_svm</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Formula
## Model: svm_poly()
## 
## -- Preprocessor ----------------------------------------------------------------
## actual ~ .
## 
## -- Model -----------------------------------------------------------------------
## Polynomial Support Vector Machine Specification (regression)
## 
## Main Arguments:
##   cost = 0.639348902476866
##   degree = 1
## 
## Computational engine: kernlab</code></pre>
</div>
<div id="model-performance-check-1" class="section level3">
<h3>Model performance check</h3>
<p>모델 성능을 확인해보았다.</p>
<pre class="r"><code>final_svm_model &lt;- finalize_model(svm_spec, best_param_svm) 

final_svm_workflow &lt;- svm_wf %&gt;% update_model(final_svm_model)

svm_fit &lt;- fit(final_svm_workflow, data = train2)

pred &lt;- predict(svm_fit, test2 %&gt;% select(-actual))
actual &lt;- test2$actual

results &lt;- tibble(pred, actual)

metrics(results, truth = actual, estimate = .pred)</code></pre>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       5.82 
## 2 rsq     standard       0.757
## 3 mae     standard       4.04</code></pre>
</div>
<div id="feature-importance-plot-1" class="section level3">
<h3>Feature importance plot</h3>
<pre class="r"><code>library(vip)

imp_svm_spec &lt;- svm_spec %&gt;%
  finalize_model(best_param_svm) %&gt;%
    set_engine(&#39;kernlab&#39;) 

svm_fit %&gt;% 
    pull_workflow_fit() %&gt;% 
    vip(method = &#39;permute&#39;, target = &quot;actual&quot;, metric = &quot;rsquared&quot;,
      pred_wrapper = kernlab::predict, train = train2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="추가-모델-fitting" class="section level1">
<h1>추가 모델 fitting</h1>
<ul>
<li><p>LASSO</p></li>
<li><p>Ridge</p></li>
<li><p>Elastic Net</p></li>
<li><p>Decision Tree</p></li>
</ul>
<pre class="r"><code>library(stacks)
# stacks 
ctrl_grid &lt;- control_stack_grid()

# LASSO 
lasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% # mixture = 1 : LASSO, 0 : ridge 
  set_engine(&quot;glmnet&quot;)

# Ridge 
ridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% # mixture = 1 : LASSO, 0 : ridge 
  set_engine(&quot;glmnet&quot;)

# elastic net 
elastic_spec &lt;- linear_reg(penalty = tune(), mixture = tune()) %&gt;%  
  set_engine(&quot;glmnet&quot;)


# Decision tree 
tree_spec &lt;- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) %&gt;%
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;regression&quot;)</code></pre>
<pre class="r"><code>lasso_wf &lt;- workflow() %&gt;% 
    add_formula(actual ~.) %&gt;% 
    add_model(lasso_spec)

ridge_wf &lt;- workflow() %&gt;% 
    add_formula(actual ~.) %&gt;% 
    add_model(ridge_spec)

elastic_wf &lt;- workflow() %&gt;% 
    add_formula(actual ~.) %&gt;% 
    add_model(elastic_spec)

tree_wf &lt;- workflow() %&gt;% 
    add_formula(actual ~.) %&gt;% 
    add_model(tree_spec)</code></pre>
<pre class="r"><code>lambda_grid &lt;- grid_regular(penalty(), levels = 10)
elastic_grid &lt;- grid_regular(penalty(), mixture(), levels = 10)
tree_grid &lt;- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 4)


lasso_res &lt;- tune_grid(
    lasso_wf, 
    resamples = vb_folds, 
    grid = lambda_grid, 
    control = ctrl_grid, 
)

ridge_res &lt;- tune_grid(
    ridge_wf, 
    resamples = vb_folds, 
    grid = lambda_grid, 
    control = ctrl_grid, 
)

elastic_res &lt;- tune_grid(
    elastic_wf, 
    resamples = vb_folds, 
    grid = elastic_grid, 
    control = ctrl_grid, 
)

tree_res &lt;- tune_grid(
  tree_wf, 
  resamples = vb_folds, 
  grid = tree_grid, 
  control = ctrl_grid, 
)</code></pre>
<div id="trace-plot" class="section level3">
<h3>trace plot</h3>
<pre class="r"><code>lasso_res %&gt;% 
    collect_metrics() %&gt;% 
    ggplot(aes(penalty, mean, color = .metric)) + # .metric : rmse 
    geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err), alpha = 0.5) + 
    geom_line(size = 1.5, show.legend = F) + 
    facet_wrap(~.metric, scales = &#39;free&#39;, nrow = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>best_param_lasso &lt;- select_best(lasso_res, &#39;rmse&#39;)
final_lasso &lt;- finalize_workflow(lasso_wf, best_param_lasso)
lasso_fit &lt;- fit(final_lasso, data = training(splits))

best_param_ridge &lt;- select_best(ridge_res, &#39;rmse&#39;)
final_ridge &lt;- finalize_workflow(ridge_wf, best_param_ridge)
ridge_fit &lt;- fit(final_ridge, data = training(splits))

best_param_elastic &lt;- select_best(elastic_res, &#39;rmse&#39;)
final_elastic &lt;- finalize_workflow(elastic_wf, best_param_elastic)
elastic_fit &lt;- fit(final_elastic, data = training(splits))

best_param_tree &lt;- select_best(tree_res, &#39;rmse&#39;)
final_tree &lt;- finalize_workflow(tree_wf, best_param_tree)
tree_fit &lt;- fit(final_tree, data = training(splits))</code></pre>
<pre class="r"><code>pred_lasso &lt;- 
    predict(lasso_fit, testing(splits)) %&gt;% 
    mutate(modelo = &quot;LASSO&quot;)

pred_ridge &lt;- 
    predict(ridge_fit, testing(splits)) %&gt;% 
    mutate(modelo = &quot;RIDGE&quot;)

pred_elastic &lt;- 
    predict(elastic_fit, testing(splits)) %&gt;% 
    mutate(modelo = &quot;ELASTIC&quot;)

pred_tree &lt;- 
    predict(tree_fit, testing(splits)) %&gt;% 
    mutate(modelo = &quot;TREE&quot;)</code></pre>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## 필요한 패키지를 로딩중입니다: lattice</code></pre>
<pre><code>## 
## 다음의 패키지를 부착합니다: &#39;caret&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:yardstick&#39;:
## 
##     precision, recall, sensitivity, specificity</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<pre class="r"><code>print(RMSE(pred_lasso$.pred, testing(splits)$actual))</code></pre>
<pre><code>## [1] 5.76062</code></pre>
<pre class="r"><code>print(RMSE(pred_ridge$.pred, testing(splits)$actual))</code></pre>
<pre><code>## [1] 5.570424</code></pre>
<pre class="r"><code>print(RMSE(pred_elastic$.pred, testing(splits)$actual))</code></pre>
<pre><code>## [1] 5.76062</code></pre>
<pre class="r"><code>print(RMSE(pred_tree$.pred, testing(splits)$actual))</code></pre>
<pre><code>## [1] 5.739863</code></pre>
<pre class="r"><code>library(vip)

tree_fit %&gt;%
  pull_workflow_fit() %&gt;% 
  vip(geom = &#39;col&#39;) # geom = &#39;point&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="stacking-with-tidymodels" class="section level2">
<h2>stacking with tidymodels</h2>
<pre class="r"><code>stacking_model &lt;- 
  # initialize the stack
  stacks() %&gt;%
  # add candidate members
  add_candidates(lasso_res) %&gt;%
  add_candidates(ridge_res) %&gt;%
  add_candidates(elastic_res) %&gt;%
  add_candidates(tree_res) %&gt;%

  # determine how to combine their predictions
  blend_predictions() %&gt;%
  # fit the candidates with nonzero stacking coefficients
  fit_members()</code></pre>
<pre><code>## Warning: Predictions from 7 candidates were identical to those from existing
## * candidates and were removed from the data stack.</code></pre>
<pre><code>## Warning: Predictions from 9 candidates were identical to those from existing
## * candidates and were removed from the data stack.</code></pre>
<pre><code>## Warning: Predictions from 76 candidates were identical to those from existing
## * candidates and were removed from the data stack.</code></pre>
<pre><code>## Warning: Predictions from 52 candidates were identical to those from existing
## * candidates and were removed from the data stack.</code></pre>
<pre class="r"><code>stacking_pred &lt;-
  test2 %&gt;%
  bind_cols(predict(stacking_model, .))


print(RMSE(stacking_pred$.pred, testing(splits)$actual))</code></pre>
<pre><code>## [1] 5.628024</code></pre>
</div>
<div id="support-vector-machine-svm" class="section level2">
<h2>Support Vector Machine (SVM)</h2>
<ol style="list-style-type: decimal">
<li><p>장점</p>
<ul>
<li>범주나 수치 예측 문제에 대해 사용할 수 있음</li>
<li>노이즈 데이터에 영향을 크게 받지 않고 잘 과적합화되지 않음</li>
<li>특히 잘 지원되는 일부 SVM 알고리즘 때문에 신경망보다 사용하기 쉬움</li>
<li>높은 정확도와 높은 프로필로 데이터 마이닝 경쟁에서 우승해 인기를 얻음</li>
</ul></li>
<li><p>단점</p>
<ul>
<li>최적의 모델을 찾기 위해 커널과 모델에서 매개변수의 여러 가지 조합 테스트가 필요함</li>
<li>특히 입력 데이터셋이 예제 개수와 속성의 수가 많다면 훈련이 느릴 수 있음</li>
<li>해석하기 불가능하지 않지만, 어렵고 복잡한 블랙박스를 만듦</li>
</ul></li>
</ol>
</div>
<div id="random-forest-rf" class="section level2">
<h2>Random Forest (RF)</h2>
<ol style="list-style-type: decimal">
<li><p>장점</p>
<ul>
<li>범주나 수치 예측 문제에 대해 사용할 수 있음</li>
<li>결측치, 명목 속성, 수치를 처리할 수 있는 자동성 학습</li>
<li>다른 모델에 비해 상대적으로 높은 성능으로 BASELINE 모델로 많이 사용</li>
</ul></li>
<li><p>단점</p>
<ul>
<li>모델이 과적합되기 쉬움</li>
<li>하이퍼 파라미터가 많음</li>
<li>모델 학습속도가 느림</li>
</ul></li>
</ol>
</div>
<div id="두-모델-중에-어떤-모델이-좋은지-선택하고-설명하기" class="section level2">
<h2>두 모델 중에 어떤 모델이 좋은지 선택하고 설명하기</h2>
<ul>
<li>Random Forest, SVM 모델의 평가지표를 비교해보면 RMSE, RSQ, MAE 기준으로 Random Forest 모델을 최적 모형으로 선택함</li>
</ul>
</div>
<div id="선택한-모델의-한계점을-설명하고-한계점을-해결할-방법-설명하기" class="section level2">
<h2>선택한 모델의 한계점을 설명하고 한계점을 해결할 방법 설명하기</h2>
<ul>
<li><p>Random Forest 모델의 경우 하이퍼 파라미터가 너무 많고, 모델 특성상 계산 시간이 오래걸림</p></li>
<li><p>모델 성능 개선이 힘듦</p></li>
<li><p>모델 성능 개선을 위해 스태킹 앙상블 모형 고려</p></li>
<li><p>xgboost, lightgbm 등 다른 tree 모형 고려</p></li>
</ul>
</div>
</div>
<div id="tidymodels-설치-안될-경우..-제발-설치되라.." class="section level1">
<h1>tidymodels 설치 안될 경우.. (제발 설치되라..)</h1>
<p>진흥원 제공 패키지 목록</p>
<ul>
<li>caret : 머신러닝 전반에 대한 패키지</li>
<li>rsample : initial_split, vfold_cv</li>
<li>recipes : 전처리 함수</li>
<li>ranger : random forest 관련 패키지</li>
<li>e1071 : svm 관련 패키지</li>
</ul>
<div id="변수-중요도-그림" class="section level2">
<h2>변수 중요도 그림</h2>
<pre class="r"><code>rf_model &lt;- ranger::ranger(actual~., data = training(splits), importance = &#39;permutation&#39;)
ranger::importance(rf_model) %&gt;% 
  enframe(&#39;Variable&#39;, &#39;Importance&#39;) %&gt;% 
  mutate(Variable = fct_reorder(Variable, Importance)) %&gt;% 
    arrange(desc(Importance)) %&gt;% 
    ggplot(aes(x = Variable, y = Importance)) +
    geom_col() +
    coord_flip() +
    scale_fill_viridis_d(end = .7) +
    labs(title = &quot;Variable Importance&quot;, subtitle = &quot;Original Variables&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
</div>
<div id="caret을-이용한-모형-적합" class="section level2">
<h2>Caret을 이용한 모형 적합</h2>
<pre class="r"><code>library(caret)

set.seed(1234)

train_index &lt;- createDataPartition(dat$actual, p = 0.7, list = F)
train &lt;- dat[train_index, ]
test &lt;- dat[-train_index, ]


# Random Forest 
control &lt;- trainControl(method=&#39;repeatedcv&#39;, 
                        number=5, 
                        repeats=3, 
                        search=&#39;grid&#39;)

tunegrid &lt;- expand.grid(.mtry = (1:5))
rf_gridsearch &lt;- train(actual ~ ., 
                       data = train,
                       method = &#39;rf&#39;,
                       metric = &#39;RMSE&#39;,
                       tuneGrid = tunegrid)

plot(varImp(rf_gridsearch, scale = F))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre class="r"><code>predict(rf_gridsearch, newdata = test)</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 45.30000 43.80713 46.56147 47.06855 47.68543 47.71797 52.54238 52.53858 
##        9       10       11       12       13       14       15       16 
## 52.17997 53.38430 52.22801 51.55385 51.94948 51.92727 55.46753 54.58241 
##       17       18       19       20       21       22       23       24 
## 52.59790 55.11327 56.25800 56.11540 56.87725 55.19078 54.88539 59.99372 
##       25       26       27       28       29       30       31       32 
## 55.91052 56.09743 73.90014 71.40781 69.76887 68.62818 72.60403 61.36527 
##       33       34       35       36       37       38       39       40 
## 61.69367 61.64077 77.69552 74.55933 73.07363 63.84497 60.36155 62.22931 
##       41       42       43       44       45       46       47       48 
## 70.63703 73.91058 65.90631 63.16333 63.78018 64.09818 64.45174 70.93069 
##       49       50       51       52       53       54       55       56 
## 71.67913 74.30466 68.06897 67.40478 68.96727 73.42600 71.00646 71.18357 
##       57       58       59       60       61       62       63       64 
## 73.50324 73.72838 69.39938 73.95668 76.15037 81.53676 77.38580 76.88397 
##       65       66       67       68       69       70       71       72 
## 74.23675 75.05740 79.08437 74.67893 74.99718 80.88472 80.94122 77.00072 
##       73       74       75       76       77       78       79       80 
## 68.91818 69.73070 72.15450 73.80546 73.05103 71.34491 67.69594 73.70254 
##       81       82       83       84       85       86       87       88 
## 65.98685 61.34923 61.71687 61.32097 63.08331 61.11551 62.27135 59.02044 
##       89       90       91       92       93       94       95       96 
## 61.29805 60.81313 52.35683 52.76461 53.09476 51.63340 50.82047 51.46780 
##       97       98       99      100      101      102      103 
## 52.26300 49.34898 42.16597 47.26877 46.21580 46.43330 49.57668</code></pre>
<pre class="r"><code>print(RMSE(predict(rf_gridsearch, newdata = test), test$actual))</code></pre>
<pre><code>## [1] 4.769534</code></pre>
<pre class="r"><code># svm 

modelLookup(&#39;svmPoly&#39;)</code></pre>
<pre><code>##     model parameter             label forReg forClass probModel
## 1 svmPoly    degree Polynomial Degree   TRUE     TRUE      TRUE
## 2 svmPoly     scale             Scale   TRUE     TRUE      TRUE
## 3 svmPoly         C              Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>modelLookup(&#39;svmRadial&#39;)</code></pre>
<pre><code>##       model parameter label forReg forClass probModel
## 1 svmRadial     sigma Sigma   TRUE     TRUE      TRUE
## 2 svmRadial         C  Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>control &lt;- trainControl(method=&#39;repeatedcv&#39;, 
                        number=5, 
                        repeats=3, 
                        search=&#39;grid&#39;)

svm_gridsearch &lt;- train(actual ~ ., 
                       data = train,
                       method = &#39;svmRadial&#39;,
                       #preProcess = c(&quot;center&quot;,&quot;scale&quot;), 
                       tuneLength = 10, 
                       metric = &#39;RMSE&#39;)

plot(varImp(svm_gridsearch, scale = F))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<pre class="r"><code># lm

set.seed(123)
lambda &lt;- 10^seq(-3, 3, length = 100)

ridge_caret &lt;- train(actual ~ ., 
                     data = train, 
                     method = &#39;glmnet&#39;, 
                     trControl = trainControl(&#39;cv&#39;, number = 5), 
                     tuneGrid = expand.grid(alpha = 0, lambda = lambda))

coef(ridge_caret$finalModel, ridge_caret$bestTune$lambda)</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                         1
## (Intercept)  6.0960276814
## month       -0.1839457116
## week목요일  -0.7959813128
## week수요일  -0.4850620237
## week월요일  -0.5010385252
## week일요일  -1.3354342687
## week토요일  -1.1243164273
## week화요일  -0.2025023606
## day         -0.0005293471
## temp_2       0.2041691800
## temp_1       0.3278888839
## average      0.4144274867</code></pre>
<pre class="r"><code>RMSE(ridge_caret %&gt;% predict(test), test$actual)</code></pre>
<pre><code>## [1] 5.307479</code></pre>
<pre class="r"><code>lasso_caret &lt;- train(actual ~ ., 
                     data = train, 
                     method = &#39;glmnet&#39;, 
                     trControl = trainControl(&#39;cv&#39;, number = 5), 
                     tuneGrid = expand.grid(alpha = 1, lambda = lambda))</code></pre>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
## There were missing values in resampled performance measures.</code></pre>
<pre class="r"><code>coef(ridge_caret$finalModel, ridge_caret$bestTune$lambda)</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                         1
## (Intercept)  6.0960276814
## month       -0.1839457116
## week목요일  -0.7959813128
## week수요일  -0.4850620237
## week월요일  -0.5010385252
## week일요일  -1.3354342687
## week토요일  -1.1243164273
## week화요일  -0.2025023606
## day         -0.0005293471
## temp_2       0.2041691800
## temp_1       0.3278888839
## average      0.4144274867</code></pre>
<pre class="r"><code>RMSE(ridge_caret %&gt;% predict(test), test$actual)</code></pre>
<pre><code>## [1] 5.307479</code></pre>
<pre class="r"><code>elastic_caret &lt;- train(actual ~ ., 
                     data = train, 
                     method = &#39;glmnet&#39;, 
                     trControl = trainControl(&#39;cv&#39;, number = 5),
                     tuneLength = 10)

coef(elastic_caret$finalModel, elastic_caret$bestTune$lambda)</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      1
## (Intercept)  6.0877537
## month       -0.1459211
## week목요일   .        
## week수요일   .        
## week월요일   .        
## week일요일  -0.4916149
## week토요일  -0.2791148
## week화요일   .        
## day          .        
## temp_2       0.1956951
## temp_1       0.3279640
## average      0.4099242</code></pre>
<pre class="r"><code>RMSE(elastic_caret %&gt;% predict(test), test$actual)</code></pre>
<pre><code>## [1] 5.308235</code></pre>
</div>
<div id="stacking-ensemble" class="section level2">
<h2>stacking ensemble</h2>
<pre class="r"><code>library(caretEnsemble)</code></pre>
<pre><code>## 
## 다음의 패키지를 부착합니다: &#39;caretEnsemble&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stacks&#39;:
## 
##     autoplot</code></pre>
<pre><code>## The following object is masked from &#39;package:workflowsets&#39;:
## 
##     autoplot</code></pre>
<pre><code>## The following object is masked from &#39;package:tune&#39;:
## 
##     autoplot</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     autoplot</code></pre>
<pre class="r"><code>stackControl &lt;- trainControl(method=&quot;repeatedcv&quot;, number=5, repeats=2, savePredictions=TRUE) # sampling = &quot;none&quot;, &quot;down&quot;, &quot;up&quot;, &quot;smote&quot;, or &quot;rose&quot;

set.seed(123)
stack_models &lt;- caretList(actual~., 
                          data = train, 
                          trControl = stackControl, 
                          methodList = c(&#39;glmnet&#39;, &#39;rf&#39;, &#39;rpart&#39;))</code></pre>
<pre><code>## Warning in trControlCheck(x = trControl, y = target): x$savePredictions == TRUE
## is depreciated. Setting to &#39;final&#39; instead.</code></pre>
<pre><code>## Warning in trControlCheck(x = trControl, y = target): indexes not defined in
## trControl. Attempting to set them ourselves, so each model in the ensemble will
## have the same resampling indexes.</code></pre>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
## There were missing values in resampled performance measures.</code></pre>
<pre class="r"><code>summary(resamples(stack_models))</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = resamples(stack_models))
## 
## Models: glmnet, rf, rpart 
## Number of resamples: 10 
## 
## MAE 
##            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA&#39;s
## glmnet 3.122689 3.668815 3.809541 3.949813 4.271879 4.863877    0
## rf     3.339801 3.599456 3.721440 3.766782 4.055149 4.177781    0
## rpart  3.821968 4.377178 5.231721 5.015999 5.530971 6.022282    0
## 
## RMSE 
##            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA&#39;s
## glmnet 4.040409 4.567383 5.022552 5.175686 5.815207 6.382394    0
## rf     4.152289 4.556918 4.964018 4.877375 5.282155 5.417894    0
## rpart  5.167159 5.599261 6.471477 6.356112 6.927093 7.495846    0
## 
## Rsquared 
##             Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## glmnet 0.7310255 0.7868018 0.8353444 0.8186523 0.8577256 0.8774324    0
## rf     0.7724878 0.8171627 0.8397326 0.8361524 0.8664317 0.8858631    0
## rpart  0.6394261 0.6820981 0.7303919 0.7259454 0.7665300 0.8225479    0</code></pre>
<pre class="r"><code>stack.gbm &lt;- caretStack(stack_models, method=&quot;gbm&quot;, metric=&#39;RMSE&#39;, trControl=stackControl)</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      123.0786             nan     0.1000   14.7244
##      2      109.2991             nan     0.1000   13.9964
##      3       98.4431             nan     0.1000   11.1125
##      4       87.9332             nan     0.1000    9.2428
##      5       79.6132             nan     0.1000    7.5494
##      6       73.3166             nan     0.1000    6.0139
##      7       68.1705             nan     0.1000    5.7697
##      8       62.7612             nan     0.1000    5.7262
##      9       57.6793             nan     0.1000    4.6731
##     10       53.5392             nan     0.1000    3.7976
##     20       30.9191             nan     0.1000    0.7869
##     40       21.2190             nan     0.1000   -0.0424
##     60       19.9957             nan     0.1000   -0.0222
##     80       19.6747             nan     0.1000   -0.0679
##    100       19.5095             nan     0.1000   -0.0353
##    120       19.3022             nan     0.1000   -0.0921
##    140       19.0965             nan     0.1000   -0.0054
##    150       18.9889             nan     0.1000   -0.0320
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      117.7844             nan     0.1000   19.7628
##      2      101.8396             nan     0.1000   16.1600
##      3       88.7555             nan     0.1000   12.6543
##      4       77.9022             nan     0.1000   10.8069
##      5       69.1155             nan     0.1000    8.6588
##      6       61.9489             nan     0.1000    6.9842
##      7       55.2234             nan     0.1000    7.0180
##      8       49.9685             nan     0.1000    5.2422
##      9       45.4226             nan     0.1000    4.4144
##     10       41.2539             nan     0.1000    4.1907
##     20       24.3537             nan     0.1000    0.4132
##     40       19.7932             nan     0.1000   -0.0556
##     60       19.0038             nan     0.1000   -0.0962
##     80       18.3017             nan     0.1000   -0.0803
##    100       17.9772             nan     0.1000   -0.1143
##    120       17.4939             nan     0.1000   -0.1005
##    140       17.0411             nan     0.1000   -0.0367
##    150       16.8426             nan     0.1000   -0.0549
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      116.1077             nan     0.1000   23.2110
##      2       99.9933             nan     0.1000   16.3469
##      3       86.3560             nan     0.1000   13.6951
##      4       74.2097             nan     0.1000   12.0234
##      5       64.8094             nan     0.1000    9.2642
##      6       56.9383             nan     0.1000    7.5881
##      7       50.2346             nan     0.1000    5.8597
##      8       44.7371             nan     0.1000    4.7900
##      9       40.6123             nan     0.1000    4.0752
##     10       37.4156             nan     0.1000    2.9460
##     20       22.4722             nan     0.1000    0.1837
##     40       18.8219             nan     0.1000   -0.1323
##     60       17.7439             nan     0.1000   -0.2015
##     80       16.9433             nan     0.1000   -0.0505
##    100       16.2481             nan     0.1000   -0.1612
##    120       15.6924             nan     0.1000   -0.1236
##    140       15.2797             nan     0.1000   -0.1076
##    150       15.1222             nan     0.1000   -0.0911
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      122.7846             nan     0.1000   15.5875
##      2      109.0814             nan     0.1000   13.3647
##      3       97.3394             nan     0.1000   10.6152
##      4       87.7044             nan     0.1000    9.0682
##      5       79.7568             nan     0.1000    7.9085
##      6       72.9865             nan     0.1000    6.4468
##      7       66.5714             nan     0.1000    5.4142
##      8       60.4991             nan     0.1000    6.1123
##      9       56.0085             nan     0.1000    4.4114
##     10       52.1361             nan     0.1000    3.4143
##     20       30.8524             nan     0.1000    1.0023
##     40       21.8373             nan     0.1000   -0.1373
##     60       20.7265             nan     0.1000   -0.0419
##     80       20.3729             nan     0.1000   -0.0737
##    100       20.0475             nan     0.1000   -0.0902
##    120       19.8267             nan     0.1000   -0.0089
##    140       19.5704             nan     0.1000   -0.1012
##    150       19.4846             nan     0.1000   -0.0764
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.5513             nan     0.1000   20.6873
##      2      105.2284             nan     0.1000   15.3609
##      3       91.2994             nan     0.1000   13.7408
##      4       79.9767             nan     0.1000   11.5431
##      5       70.3901             nan     0.1000    8.8454
##      6       61.8781             nan     0.1000    7.4324
##      7       55.1406             nan     0.1000    5.6830
##      8       49.5380             nan     0.1000    5.3422
##      9       45.3355             nan     0.1000    4.4053
##     10       41.1618             nan     0.1000    3.4503
##     20       24.5330             nan     0.1000    0.5628
##     40       20.5806             nan     0.1000    0.0322
##     60       19.6401             nan     0.1000   -0.0587
##     80       18.9368             nan     0.1000   -0.0531
##    100       18.1114             nan     0.1000   -0.0654
##    120       17.5610             nan     0.1000   -0.0985
##    140       17.1753             nan     0.1000   -0.1714
##    150       16.9747             nan     0.1000   -0.0967
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      119.1456             nan     0.1000   21.5809
##      2      101.7272             nan     0.1000   18.2219
##      3       88.2467             nan     0.1000   12.9071
##      4       77.0577             nan     0.1000   11.1732
##      5       67.2339             nan     0.1000    9.7053
##      6       59.2450             nan     0.1000    6.3771
##      7       52.9665             nan     0.1000    6.1738
##      8       47.7257             nan     0.1000    5.0930
##      9       42.9659             nan     0.1000    4.5349
##     10       38.7999             nan     0.1000    3.8740
##     20       23.3799             nan     0.1000    0.0862
##     40       19.7121             nan     0.1000    0.0098
##     60       18.7129             nan     0.1000   -0.0843
##     80       17.7907             nan     0.1000   -0.1638
##    100       16.8418             nan     0.1000   -0.0884
##    120       16.1133             nan     0.1000   -0.0599
##    140       15.4425             nan     0.1000   -0.0855
##    150       15.1576             nan     0.1000   -0.1317
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      128.4796             nan     0.1000   17.2269
##      2      114.4947             nan     0.1000   13.6686
##      3      103.4770             nan     0.1000   12.1504
##      4       93.0429             nan     0.1000   10.1201
##      5       83.5782             nan     0.1000    9.1525
##      6       75.9609             nan     0.1000    8.2043
##      7       69.3979             nan     0.1000    6.2448
##      8       63.6054             nan     0.1000    5.7980
##      9       58.9380             nan     0.1000    4.6666
##     10       54.6098             nan     0.1000    4.9408
##     20       31.1491             nan     0.1000    1.0837
##     40       21.1260             nan     0.1000    0.0257
##     60       19.7726             nan     0.1000   -0.0515
##     80       19.3404             nan     0.1000   -0.0609
##    100       19.0298             nan     0.1000   -0.0956
##    120       18.7677             nan     0.1000   -0.0670
##    140       18.4935             nan     0.1000   -0.1128
##    150       18.4090             nan     0.1000   -0.1132
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      124.6688             nan     0.1000   20.4551
##      2      106.9241             nan     0.1000   16.7533
##      3       92.7786             nan     0.1000   13.5389
##      4       80.5069             nan     0.1000   10.6851
##      5       71.4185             nan     0.1000    8.2736
##      6       62.9725             nan     0.1000    8.1147
##      7       56.1689             nan     0.1000    7.0784
##      8       50.5750             nan     0.1000    5.5839
##      9       45.9461             nan     0.1000    4.5176
##     10       42.2147             nan     0.1000    4.3480
##     20       24.3453             nan     0.1000    0.5004
##     40       19.3507             nan     0.1000    0.0218
##     60       18.5953             nan     0.1000   -0.1142
##     80       18.0130             nan     0.1000   -0.0554
##    100       17.4551             nan     0.1000   -0.1797
##    120       17.0500             nan     0.1000   -0.0763
##    140       16.6815             nan     0.1000   -0.1099
##    150       16.4385             nan     0.1000   -0.1360
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      122.6739             nan     0.1000   21.5391
##      2      104.3494             nan     0.1000   18.8195
##      3       89.1807             nan     0.1000   15.2488
##      4       76.7250             nan     0.1000   10.7195
##      5       66.8379             nan     0.1000    8.7571
##      6       59.2678             nan     0.1000    8.0324
##      7       52.3113             nan     0.1000    6.6721
##      8       46.7328             nan     0.1000    5.7223
##      9       42.0936             nan     0.1000    4.3581
##     10       37.8599             nan     0.1000    3.6947
##     20       21.7789             nan     0.1000    0.3221
##     40       18.5540             nan     0.1000   -0.1829
##     60       17.6046             nan     0.1000   -0.0375
##     80       16.8094             nan     0.1000   -0.1178
##    100       16.1556             nan     0.1000   -0.0985
##    120       15.6860             nan     0.1000   -0.1149
##    140       15.1893             nan     0.1000   -0.0797
##    150       14.9724             nan     0.1000   -0.0768
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      127.0680             nan     0.1000   16.3034
##      2      113.7894             nan     0.1000   12.7639
##      3      102.2829             nan     0.1000   11.3003
##      4       92.1612             nan     0.1000    9.3432
##      5       83.4454             nan     0.1000    9.0895
##      6       76.9821             nan     0.1000    6.3246
##      7       70.2786             nan     0.1000    7.2195
##      8       64.8285             nan     0.1000    4.7556
##      9       60.2058             nan     0.1000    5.1791
##     10       56.0465             nan     0.1000    4.1344
##     20       33.6370             nan     0.1000    1.1498
##     40       23.7500             nan     0.1000    0.1210
##     60       22.2769             nan     0.1000   -0.0699
##     80       21.6717             nan     0.1000   -0.1599
##    100       21.3368             nan     0.1000   -0.0200
##    120       21.2272             nan     0.1000   -0.1617
##    140       20.8770             nan     0.1000   -0.1532
##    150       20.7680             nan     0.1000   -0.1194
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      124.0821             nan     0.1000   17.6845
##      2      107.4218             nan     0.1000   17.3821
##      3       92.7895             nan     0.1000   14.7272
##      4       81.3461             nan     0.1000   11.8006
##      5       71.7622             nan     0.1000    8.7843
##      6       63.8430             nan     0.1000    7.6266
##      7       57.4676             nan     0.1000    5.0539
##      8       52.1246             nan     0.1000    4.5883
##      9       46.8549             nan     0.1000    4.3671
##     10       42.9960             nan     0.1000    3.8925
##     20       25.8535             nan     0.1000    0.4799
##     40       21.4305             nan     0.1000   -0.2044
##     60       20.6240             nan     0.1000   -0.1011
##     80       19.8503             nan     0.1000   -0.0320
##    100       19.2577             nan     0.1000   -0.0658
##    120       18.7629             nan     0.1000   -0.0074
##    140       18.3712             nan     0.1000   -0.0925
##    150       18.1679             nan     0.1000   -0.0757
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      123.6494             nan     0.1000   19.2839
##      2      105.8535             nan     0.1000   18.7998
##      3       90.8840             nan     0.1000   15.5464
##      4       79.2821             nan     0.1000   13.0372
##      5       69.1741             nan     0.1000    9.9898
##      6       60.6459             nan     0.1000    7.8221
##      7       54.4690             nan     0.1000    6.1507
##      8       48.7596             nan     0.1000    5.8794
##      9       43.8136             nan     0.1000    4.4595
##     10       39.8808             nan     0.1000    3.9312
##     20       24.1376             nan     0.1000   -0.0444
##     40       20.5522             nan     0.1000   -0.1099
##     60       19.5552             nan     0.1000   -0.1138
##     80       18.5585             nan     0.1000   -0.2474
##    100       17.6430             nan     0.1000   -0.1076
##    120       17.0207             nan     0.1000   -0.1839
##    140       16.4321             nan     0.1000   -0.0816
##    150       16.1078             nan     0.1000   -0.0165
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      126.9518             nan     0.1000   16.0385
##      2      112.6926             nan     0.1000   13.2787
##      3      101.3589             nan     0.1000   11.7136
##      4       91.2252             nan     0.1000    9.5356
##      5       82.5008             nan     0.1000    8.2433
##      6       75.2034             nan     0.1000    6.9060
##      7       69.3605             nan     0.1000    6.1899
##      8       63.5195             nan     0.1000    5.5288
##      9       59.2236             nan     0.1000    4.7350
##     10       54.8643             nan     0.1000    3.6505
##     20       32.3438             nan     0.1000    0.8875
##     40       22.1173             nan     0.1000    0.1015
##     60       20.8002             nan     0.1000   -0.1407
##     80       20.4092             nan     0.1000   -0.0124
##    100       20.1696             nan     0.1000   -0.0784
##    120       19.9605             nan     0.1000   -0.0648
##    140       19.8109             nan     0.1000   -0.0476
##    150       19.7038             nan     0.1000   -0.0752
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      124.8657             nan     0.1000   18.9240
##      2      107.6926             nan     0.1000   15.2337
##      3       94.6521             nan     0.1000   14.0918
##      4       83.1014             nan     0.1000   12.0810
##      5       73.2358             nan     0.1000   10.2220
##      6       65.3625             nan     0.1000    8.0627
##      7       58.6436             nan     0.1000    6.6056
##      8       52.6975             nan     0.1000    5.8376
##      9       48.1136             nan     0.1000    3.3516
##     10       43.8928             nan     0.1000    4.1024
##     20       25.5427             nan     0.1000    0.8925
##     40       20.4445             nan     0.1000   -0.0001
##     60       19.5111             nan     0.1000   -0.0617
##     80       19.0461             nan     0.1000   -0.0866
##    100       18.5872             nan     0.1000   -0.0366
##    120       18.0910             nan     0.1000   -0.1142
##    140       17.4642             nan     0.1000   -0.0874
##    150       17.2302             nan     0.1000   -0.0363
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      123.0427             nan     0.1000   21.1288
##      2      105.3487             nan     0.1000   19.2594
##      3       91.6676             nan     0.1000   14.4848
##      4       79.5296             nan     0.1000   12.2300
##      5       69.1572             nan     0.1000   10.0797
##      6       60.9880             nan     0.1000    7.4279
##      7       54.0409             nan     0.1000    6.8167
##      8       48.3798             nan     0.1000    5.1763
##      9       43.8147             nan     0.1000    4.9087
##     10       39.7484             nan     0.1000    3.7354
##     20       23.4412             nan     0.1000    0.5424
##     40       19.9305             nan     0.1000   -0.4261
##     60       18.9978             nan     0.1000   -0.1363
##     80       18.1546             nan     0.1000   -0.1394
##    100       17.2591             nan     0.1000   -0.1865
##    120       16.5421             nan     0.1000   -0.0844
##    140       16.0136             nan     0.1000   -0.0865
##    150       15.7207             nan     0.1000   -0.0979
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      123.2424             nan     0.1000   15.9684
##      2      109.6718             nan     0.1000   13.4276
##      3       98.6161             nan     0.1000   10.6970
##      4       88.9366             nan     0.1000    9.1206
##      5       81.0477             nan     0.1000    7.5903
##      6       73.8669             nan     0.1000    6.6700
##      7       67.8724             nan     0.1000    5.5422
##      8       61.9934             nan     0.1000    5.1143
##      9       57.3018             nan     0.1000    4.4161
##     10       53.1581             nan     0.1000    3.7042
##     20       31.6939             nan     0.1000    0.7414
##     40       21.9594             nan     0.1000    0.0450
##     60       20.6425             nan     0.1000   -0.0164
##     80       20.1220             nan     0.1000   -0.0696
##    100       19.8537             nan     0.1000   -0.0261
##    120       19.5912             nan     0.1000    0.0010
##    140       19.3723             nan     0.1000   -0.0946
##    150       19.2637             nan     0.1000   -0.1381
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      119.9022             nan     0.1000   18.6932
##      2      103.7244             nan     0.1000   15.4798
##      3       89.5237             nan     0.1000   14.3376
##      4       78.8798             nan     0.1000   10.5923
##      5       69.7656             nan     0.1000    8.1424
##      6       61.7820             nan     0.1000    7.5631
##      7       55.5780             nan     0.1000    5.8484
##      8       50.2321             nan     0.1000    5.1001
##      9       46.1738             nan     0.1000    4.0456
##     10       42.1410             nan     0.1000    4.0581
##     20       24.8007             nan     0.1000    0.2809
##     40       20.1490             nan     0.1000   -0.0806
##     60       19.3915             nan     0.1000   -0.0306
##     80       18.7013             nan     0.1000   -0.0702
##    100       17.9674             nan     0.1000   -0.1491
##    120       17.6161             nan     0.1000   -0.1135
##    140       17.1651             nan     0.1000   -0.1002
##    150       16.9767             nan     0.1000   -0.0767
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      117.3286             nan     0.1000   22.7481
##      2      100.7852             nan     0.1000   16.1103
##      3       86.9634             nan     0.1000   13.5788
##      4       74.6947             nan     0.1000   11.1127
##      5       64.5826             nan     0.1000   10.0566
##      6       56.6629             nan     0.1000    7.2485
##      7       50.1649             nan     0.1000    5.7443
##      8       44.8102             nan     0.1000    5.0723
##      9       40.0140             nan     0.1000    3.8968
##     10       36.4936             nan     0.1000    3.0181
##     20       22.4323             nan     0.1000    0.4242
##     40       19.3411             nan     0.1000   -0.1425
##     60       18.2185             nan     0.1000   -0.2168
##     80       17.4995             nan     0.1000   -0.1683
##    100       16.7780             nan     0.1000   -0.0903
##    120       16.2229             nan     0.1000   -0.1612
##    140       15.8318             nan     0.1000   -0.0407
##    150       15.6123             nan     0.1000   -0.0835
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      126.7950             nan     0.1000   16.7415
##      2      113.1265             nan     0.1000   13.3815
##      3      102.3816             nan     0.1000   10.5782
##      4       91.9297             nan     0.1000    9.8232
##      5       82.3842             nan     0.1000    8.3491
##      6       75.1038             nan     0.1000    6.8498
##      7       68.0588             nan     0.1000    6.4805
##      8       62.8333             nan     0.1000    5.3539
##      9       58.7247             nan     0.1000    3.9054
##     10       53.9969             nan     0.1000    4.1992
##     20       30.7469             nan     0.1000    1.0129
##     40       21.0114             nan     0.1000    0.1301
##     60       19.7089             nan     0.1000   -0.0078
##     80       19.2819             nan     0.1000   -0.0797
##    100       19.0264             nan     0.1000   -0.0349
##    120       18.8823             nan     0.1000   -0.1254
##    140       18.6516             nan     0.1000   -0.0412
##    150       18.5414             nan     0.1000   -0.1191
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      122.7557             nan     0.1000   19.7904
##      2      106.2242             nan     0.1000   16.1260
##      3       92.8416             nan     0.1000   12.7335
##      4       82.0170             nan     0.1000   11.0028
##      5       72.7623             nan     0.1000    8.2352
##      6       64.1952             nan     0.1000    8.5855
##      7       57.4886             nan     0.1000    6.5133
##      8       51.2257             nan     0.1000    4.7768
##      9       46.0117             nan     0.1000    4.7937
##     10       41.9173             nan     0.1000    3.6909
##     20       23.4581             nan     0.1000    0.7501
##     40       19.5831             nan     0.1000   -0.0783
##     60       18.8706             nan     0.1000   -0.1685
##     80       18.1518             nan     0.1000   -0.0909
##    100       17.7408             nan     0.1000   -0.0756
##    120       17.2596             nan     0.1000   -0.0953
##    140       16.8179             nan     0.1000   -0.1737
##    150       16.6165             nan     0.1000   -0.1404
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.5014             nan     0.1000   20.2892
##      2      102.9172             nan     0.1000   16.7144
##      3       88.2934             nan     0.1000   14.5377
##      4       76.5774             nan     0.1000   12.0382
##      5       66.5172             nan     0.1000    9.8390
##      6       57.9635             nan     0.1000    8.7342
##      7       51.2975             nan     0.1000    6.2879
##      8       45.7741             nan     0.1000    4.9730
##      9       41.4710             nan     0.1000    4.5473
##     10       37.6915             nan     0.1000    3.3709
##     20       21.6542             nan     0.1000    0.3928
##     40       18.3504             nan     0.1000   -0.1808
##     60       17.4567             nan     0.1000   -0.0845
##     80       16.5566             nan     0.1000   -0.0873
##    100       15.8562             nan     0.1000   -0.2441
##    120       15.3423             nan     0.1000   -0.0810
##    140       14.8514             nan     0.1000   -0.2018
##    150       14.6294             nan     0.1000   -0.0701
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      125.6999             nan     0.1000   16.3399
##      2      112.3713             nan     0.1000   13.3563
##      3      101.1314             nan     0.1000   11.4956
##      4       91.2000             nan     0.1000    9.9035
##      5       82.8425             nan     0.1000    8.9450
##      6       75.7827             nan     0.1000    6.4886
##      7       69.0875             nan     0.1000    6.4160
##      8       63.4774             nan     0.1000    5.2609
##      9       58.9489             nan     0.1000    4.1325
##     10       54.3137             nan     0.1000    4.1551
##     20       30.8801             nan     0.1000    1.0707
##     40       21.4564             nan     0.1000    0.1243
##     60       19.9686             nan     0.1000   -0.0086
##     80       19.5316             nan     0.1000   -0.0370
##    100       19.2536             nan     0.1000   -0.1864
##    120       19.0088             nan     0.1000   -0.1350
##    140       18.8028             nan     0.1000   -0.0569
##    150       18.6733             nan     0.1000   -0.1136
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.5188             nan     0.1000   18.4228
##      2      105.0641             nan     0.1000   16.5149
##      3       92.7233             nan     0.1000   13.5887
##      4       79.8901             nan     0.1000   12.3480
##      5       70.0520             nan     0.1000    9.1768
##      6       62.1910             nan     0.1000    7.0229
##      7       55.4414             nan     0.1000    6.6726
##      8       49.7967             nan     0.1000    5.4916
##      9       44.8493             nan     0.1000    4.7328
##     10       41.0261             nan     0.1000    4.1597
##     20       23.7481             nan     0.1000    0.6782
##     40       18.9478             nan     0.1000   -0.0863
##     60       18.1273             nan     0.1000   -0.3056
##     80       17.4558             nan     0.1000   -0.1077
##    100       16.9814             nan     0.1000   -0.0593
##    120       16.3571             nan     0.1000   -0.0555
##    140       15.9227             nan     0.1000   -0.0752
##    150       15.6771             nan     0.1000   -0.0626
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.4061             nan     0.1000   21.6082
##      2      103.2129             nan     0.1000   17.9646
##      3       87.8577             nan     0.1000   14.3963
##      4       75.6347             nan     0.1000   11.1673
##      5       65.7926             nan     0.1000   10.0130
##      6       57.1429             nan     0.1000    7.1796
##      7       50.4381             nan     0.1000    6.1916
##      8       45.7520             nan     0.1000    4.5231
##      9       41.1912             nan     0.1000    4.5168
##     10       37.7570             nan     0.1000    3.6713
##     20       22.1523             nan     0.1000    0.5590
##     40       18.1894             nan     0.1000   -0.0476
##     60       17.1015             nan     0.1000   -0.1330
##     80       16.2860             nan     0.1000   -0.1511
##    100       15.6297             nan     0.1000   -0.1956
##    120       15.0296             nan     0.1000   -0.0875
##    140       14.3194             nan     0.1000   -0.1581
##    150       14.1348             nan     0.1000   -0.0737
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      126.1517             nan     0.1000   15.8100
##      2      111.8710             nan     0.1000   13.4024
##      3       99.3164             nan     0.1000   11.6884
##      4       89.3288             nan     0.1000    9.2526
##      5       80.0203             nan     0.1000    7.2017
##      6       72.8847             nan     0.1000    6.2964
##      7       66.9092             nan     0.1000    6.1521
##      8       62.1589             nan     0.1000    4.6809
##      9       56.8597             nan     0.1000    4.2788
##     10       53.4325             nan     0.1000    3.5910
##     20       32.2810             nan     0.1000    0.9760
##     40       23.3181             nan     0.1000    0.1425
##     60       21.9477             nan     0.1000    0.0016
##     80       21.6706             nan     0.1000   -0.0368
##    100       21.3365             nan     0.1000   -0.0941
##    120       21.1318             nan     0.1000   -0.0557
##    140       20.9851             nan     0.1000   -0.1523
##    150       20.9053             nan     0.1000   -0.1067
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      124.0774             nan     0.1000   18.8134
##      2      108.1332             nan     0.1000   16.4866
##      3       93.4586             nan     0.1000   11.7136
##      4       82.3487             nan     0.1000   10.5868
##      5       73.0685             nan     0.1000    7.8019
##      6       64.7686             nan     0.1000    8.4717
##      7       58.3533             nan     0.1000    7.0444
##      8       52.5829             nan     0.1000    5.6906
##      9       47.8878             nan     0.1000    4.0353
##     10       43.6329             nan     0.1000    4.1678
##     20       25.6630             nan     0.1000    0.5982
##     40       21.5403             nan     0.1000   -0.0873
##     60       20.6176             nan     0.1000   -0.1422
##     80       20.1062             nan     0.1000   -0.0957
##    100       19.5417             nan     0.1000   -0.0507
##    120       19.0921             nan     0.1000   -0.0619
##    140       18.4736             nan     0.1000   -0.1276
##    150       18.2266             nan     0.1000   -0.0216
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.5975             nan     0.1000   21.6039
##      2      104.0205             nan     0.1000   16.8351
##      3       89.7488             nan     0.1000   13.3192
##      4       78.5076             nan     0.1000   10.9503
##      5       68.6543             nan     0.1000    9.1716
##      6       60.2496             nan     0.1000    7.8828
##      7       53.2888             nan     0.1000    6.6209
##      8       47.3684             nan     0.1000    5.4583
##      9       42.5943             nan     0.1000    4.1074
##     10       39.0768             nan     0.1000    3.0234
##     20       24.0743             nan     0.1000    0.3358
##     40       20.5825             nan     0.1000   -0.0189
##     60       19.6131             nan     0.1000   -0.0716
##     80       18.6531             nan     0.1000   -0.2488
##    100       17.8546             nan     0.1000   -0.1413
##    120       17.2060             nan     0.1000   -0.1729
##    140       16.5824             nan     0.1000   -0.2662
##    150       16.2743             nan     0.1000   -0.1398
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      127.5202             nan     0.1000   16.4273
##      2      114.1511             nan     0.1000   13.2386
##      3      102.3099             nan     0.1000   12.1352
##      4       92.8578             nan     0.1000    9.5656
##      5       84.5214             nan     0.1000    8.6311
##      6       76.7649             nan     0.1000    7.1543
##      7       70.2665             nan     0.1000    7.0482
##      8       65.0537             nan     0.1000    5.5003
##      9       60.3053             nan     0.1000    5.1713
##     10       56.0921             nan     0.1000    4.0072
##     20       32.6411             nan     0.1000    0.8298
##     40       22.6373             nan     0.1000    0.0142
##     60       21.1160             nan     0.1000   -0.0097
##     80       20.6009             nan     0.1000   -0.0942
##    100       20.2417             nan     0.1000   -0.0774
##    120       20.0163             nan     0.1000   -0.0910
##    140       19.8490             nan     0.1000   -0.0554
##    150       19.7786             nan     0.1000   -0.0454
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      126.7109             nan     0.1000   18.4528
##      2      110.0622             nan     0.1000   17.6660
##      3       95.5380             nan     0.1000   15.2171
##      4       83.3017             nan     0.1000   10.9996
##      5       73.7858             nan     0.1000    9.5001
##      6       65.7032             nan     0.1000    7.8279
##      7       58.2701             nan     0.1000    7.1424
##      8       52.8690             nan     0.1000    5.8292
##      9       48.1891             nan     0.1000    4.4899
##     10       44.0240             nan     0.1000    4.0365
##     20       25.6678             nan     0.1000    0.2152
##     40       21.1584             nan     0.1000   -0.0768
##     60       20.2001             nan     0.1000   -0.2311
##     80       19.4599             nan     0.1000   -0.0745
##    100       18.6030             nan     0.1000   -0.0050
##    120       18.1444             nan     0.1000   -0.1065
##    140       17.7051             nan     0.1000   -0.1807
##    150       17.5356             nan     0.1000   -0.1031
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      121.9870             nan     0.1000   22.4829
##      2      103.9765             nan     0.1000   17.7907
##      3       89.2553             nan     0.1000   15.6439
##      4       77.8671             nan     0.1000   10.7588
##      5       68.7606             nan     0.1000    8.8518
##      6       60.3827             nan     0.1000    6.9086
##      7       53.2890             nan     0.1000    6.3130
##      8       47.4879             nan     0.1000    4.8011
##      9       42.5445             nan     0.1000    4.1970
##     10       39.0692             nan     0.1000    3.7781
##     20       23.8371             nan     0.1000    0.4548
##     40       19.9090             nan     0.1000   -0.0584
##     60       18.5175             nan     0.1000   -0.3068
##     80       17.7570             nan     0.1000   -0.2474
##    100       17.0380             nan     0.1000   -0.2085
##    120       16.3332             nan     0.1000   -0.1198
##    140       15.6842             nan     0.1000   -0.1634
##    150       15.3829             nan     0.1000   -0.0494
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1      122.9987             nan     0.1000   19.9163
##      2      105.9021             nan     0.1000   16.3435
##      3       92.2039             nan     0.1000   13.0638
##      4       80.3052             nan     0.1000   10.8827
##      5       71.1242             nan     0.1000    9.0450
##      6       62.7965             nan     0.1000    7.8543
##      7       55.8698             nan     0.1000    6.4227
##      8       50.5068             nan     0.1000    5.0114
##      9       46.2043             nan     0.1000    4.2735
##     10       42.3324             nan     0.1000    3.8538
##     20       24.8094             nan     0.1000    0.6139
##     40       20.4883             nan     0.1000   -0.0766
##     50       20.0331             nan     0.1000   -0.1248</code></pre>
<pre class="r"><code>stack.glm &lt;- caretStack(stack_models, method=&quot;glm&quot;, metric=&#39;RMSE&#39;, trControl=stackControl)

pred_stack_gbm &lt;- predict(stack.gbm, newdata=test)
pred_stack_glm &lt;- predict(stack.glm, newdata=test)

RMSE(pred_stack_gbm, test$actual)</code></pre>
<pre><code>## [1] 4.867208</code></pre>
<pre class="r"><code>RMSE(pred_stack_glm, test$actual)</code></pre>
<pre><code>## [1] 4.733712</code></pre>
</div>
</div>
<div id="참고자료" class="section level1">
<h1>참고자료</h1>
<p><a href="https://towardsdatascience.com/random-forest-in-python-24d0893d51c0" class="uri">https://towardsdatascience.com/random-forest-in-python-24d0893d51c0</a></p>
<p><a href="https://cran.r-project.org/web/packages/stacks/vignettes/classification.html" class="uri">https://cran.r-project.org/web/packages/stacks/vignettes/classification.html</a></p>
<p><a href="https://github.com/tidymodels/stacks" class="uri">https://github.com/tidymodels/stacks</a></p>
<p><a href="https://juliasilge.com/blog/wind-turbine/" class="uri">https://juliasilge.com/blog/wind-turbine/</a></p>
<p><a href="https://dzone.com/articles/build-custom-ensemble-models-using-caret-in-r" class="uri">https://dzone.com/articles/build-custom-ensemble-models-using-caret-in-r</a></p>
<p><a href="https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html" class="uri">https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html</a></p>
<p><a href="https://rpubs.com/uky994/593668" class="uri">https://rpubs.com/uky994/593668</a></p>
<p><a href="https://topepo.github.io/caret/train-models-by-tag.html#linear-regression" class="uri">https://topepo.github.io/caret/train-models-by-tag.html#linear-regression</a></p>
<p>브레트 란츠 저, R을 활용한 기계학습</p>
</div>
