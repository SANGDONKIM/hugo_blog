---
title: Tidymodels tutorial
author: dondon
date: '2021-03-06'
slug: tidymodels-tutorial
categories:
  - statistics
tags:
  - Machine learning
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="tidymodels-tutorial" class="section level1">
<h1>tidymodels tutorial</h1>
<p>tidymodels는 R 유저라면 한번쯤 써봤을 패키지인 tidyverse와 결이 같은 패키지이다. tidyverse가 데이터 전처리, 시각화를 간결한 파이프라인으로 만들 수 있는 것과 마찬가지로, tidymodels는 데이터 모델링 관점에서의 데이터 전처리, 모델링, 시각화 등을 쉽게 할 수 있게 고안된 패키지이다. tidyverse 수준으로 굉장히 완성도가 있고, R을 좋아하는 진성 유저들이 기존에 존재하는 패키지를 tidymodels와 결합하거나 새로운 함수를 끊임없이 만들고 있는 중이다.</p>
</div>
<div id="tidymodels-설치-방법" class="section level1">
<h1>tidymodels 설치 방법</h1>
<p>tidymodels는 cran에 정식 등록된 패키지이므로 install_packages()로 설치가 가능하다. 설치 오류가 가끔 있는데 r 패키지를 전부 최신 버전으로 업데이트하면 오류 없이 설치가 가능하다.</p>
<p>tidymodels 패키지에는 예제 데이터로 ames 데이터가 내장되어있다. 간결한 설명을 위해 예제 데이터를 이용한다.</p>
<pre class="r"><code>data(ames)
ames &lt;- ames %&gt;% janitor::clean_names()
head(ames)</code></pre>
<pre><code>## # A tibble: 6 x 74
##   ms_sub_class      ms_zoning    lot_frontage lot_area street alley   lot_shape 
##   &lt;fct&gt;             &lt;fct&gt;               &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;fct&gt;     
## 1 One_Story_1946_a~ Residential~          141    31770 Pave   No_All~ Slightly_~
## 2 One_Story_1946_a~ Residential~           80    11622 Pave   No_All~ Regular   
## 3 One_Story_1946_a~ Residential~           81    14267 Pave   No_All~ Slightly_~
## 4 One_Story_1946_a~ Residential~           93    11160 Pave   No_All~ Regular   
## 5 Two_Story_1946_a~ Residential~           74    13830 Pave   No_All~ Slightly_~
## 6 Two_Story_1946_a~ Residential~           78     9978 Pave   No_All~ Slightly_~
## # ... with 67 more variables: land_contour &lt;fct&gt;, utilities &lt;fct&gt;,
## #   lot_config &lt;fct&gt;, land_slope &lt;fct&gt;, neighborhood &lt;fct&gt;, condition_1 &lt;fct&gt;,
## #   condition_2 &lt;fct&gt;, bldg_type &lt;fct&gt;, house_style &lt;fct&gt;, overall_cond &lt;fct&gt;,
## #   year_built &lt;int&gt;, year_remod_add &lt;int&gt;, roof_style &lt;fct&gt;, roof_matl &lt;fct&gt;,
## #   exterior_1st &lt;fct&gt;, exterior_2nd &lt;fct&gt;, mas_vnr_type &lt;fct&gt;,
## #   mas_vnr_area &lt;dbl&gt;, exter_cond &lt;fct&gt;, foundation &lt;fct&gt;, bsmt_cond &lt;fct&gt;,
## #   bsmt_exposure &lt;fct&gt;, bsmt_fin_type_1 &lt;fct&gt;, bsmt_fin_sf_1 &lt;dbl&gt;,
## #   bsmt_fin_type_2 &lt;fct&gt;, bsmt_fin_sf_2 &lt;dbl&gt;, bsmt_unf_sf &lt;dbl&gt;,
## #   total_bsmt_sf &lt;dbl&gt;, heating &lt;fct&gt;, heating_qc &lt;fct&gt;, central_air &lt;fct&gt;,
## #   electrical &lt;fct&gt;, first_flr_sf &lt;int&gt;, second_flr_sf &lt;int&gt;,
## #   gr_liv_area &lt;int&gt;, bsmt_full_bath &lt;dbl&gt;, bsmt_half_bath &lt;dbl&gt;,
## #   full_bath &lt;int&gt;, half_bath &lt;int&gt;, bedroom_abv_gr &lt;int&gt;,
## #   kitchen_abv_gr &lt;int&gt;, tot_rms_abv_grd &lt;int&gt;, functional &lt;fct&gt;,
## #   fireplaces &lt;int&gt;, garage_type &lt;fct&gt;, garage_finish &lt;fct&gt;,
## #   garage_cars &lt;dbl&gt;, garage_area &lt;dbl&gt;, garage_cond &lt;fct&gt;, paved_drive &lt;fct&gt;,
## #   wood_deck_sf &lt;int&gt;, open_porch_sf &lt;int&gt;, enclosed_porch &lt;int&gt;,
## #   three_season_porch &lt;int&gt;, screen_porch &lt;int&gt;, pool_area &lt;int&gt;,
## #   pool_qc &lt;fct&gt;, fence &lt;fct&gt;, misc_feature &lt;fct&gt;, misc_val &lt;int&gt;,
## #   mo_sold &lt;int&gt;, year_sold &lt;int&gt;, sale_type &lt;fct&gt;, sale_condition &lt;fct&gt;,
## #   sale_price &lt;int&gt;, longitude &lt;dbl&gt;, latitude &lt;dbl&gt;</code></pre>
</div>
<div id="data-split" class="section level1">
<h1>Data split</h1>
<p>데이터 모델링을 진행할 때 홀드 아웃 방식으로 train set과 test set을 나누는 과정을 거친다(validation set을 추가할 수도 있다). 보통 train set, test set을 5:5, 7:3, 8:2 등의 비율로 random sampling을 통해 나누고, 특정 변수가 불균형인 경우에는 층화추출을 이용하기도 한다. tidymodels에서는 이렇게 데이터를 분할하는 과정을 <strong>initial_split()</strong> 을 이용해서 간단하게 처리할 수 있다. <strong>initial_split()</strong> 을 통해 분할된 데이터는 <strong>training()</strong>, <strong>testing()</strong> 함수를 이용해서 호출하고, train set, test set을 구축할 수 있다.</p>
<p>기본적으로 random sampling을 통해 데이터를 나누지만 범주형 변수의 category 빈도가 불균형할 경우, 연속형 변수의 분포가 치우쳐져있을 경우 random sampling이 적절하지 않을 수 있다. 이 때 <strong>strata</strong> 옵션을 이용하면 간단하게 해결할 수 있다.</p>
<p><strong>initial_split()</strong></p>
<ul>
<li>prop : train set 비율</li>
<li>strata : 범주간 불균형 문제를 해결하기 위해 층을 나누고 서브샘플링. 연속형 변수의 경우 사분위수를 기준으로 데이터를 나누고 서브샘플링</li>
</ul>
<pre class="r"><code>set.seed(2021)
ames_split &lt;- initial_split(ames, prop = 0.8, strata = sale_price)
ames_train &lt;- training(ames_split)
ames_test &lt;- testing(ames_split)</code></pre>
</div>
<div id="feature-engineering" class="section level1">
<h1>Feature engineering</h1>
<p>tidymodels 는 복잡한 데이터 전처리 과정을 간소화시키기 위해서 총 3단계의 데이터 전처리 프로세스를 도입했다. 각 단계는 recipe(요리 방식을 정의하는 단계), prep(요리 재료를 준비하는 단계), bake(요리를 하는 단계)로 구성된다.</p>
<p>각 단계별로 살펴보면 첫 번째로, recipe는 사전에 처리할 함수를 정의하는 단계이다. recipe와 연동되는 데이터 전처리에 필요한 함수가 사전 정의되어 있으며, 이를 이용해서 데이터 전처리 과정을 정의한다. 두 번째로, prep은 training set으로 부터 recipe에서 정의한 데이터 전처리 과정을 계산하는 단계이다. 계산 결과를 바로 output으로 출력되지는 않는다. 세 번째로, bake는 recipe, prep을 이용해서 계산된 전처리 방식을 output으로 출력하는 단계이다.</p>
<p>사실 사용하면서 데이터 전처리 과정을 사전 정의한다는 개념이 익숙하지 않았는데 각 단계별 세부 내용을 기술하면서 나름의 이유를 설명해보도록 하겠다.</p>
<div id="recipe" class="section level2">
<h2>Recipe</h2>
<p>데이터 전처리를 위한 단계를 정의하는 object이다. 특이한 점은 즉시 실행되지 않고 단계를 <strong>정의</strong>만한다는 것이다. 왜 번거롭게 recipe를 사용해야 하는지 의문이 생길 수 있다.</p>
<p>Recipe의 장점은 다음과 같다.</p>
<ul>
<li><p>recipe object를 여러가지 모델에 재사용 가능</p></li>
<li><p>recipe 내에 사전 정의된 함수를 이용하면 코드의 간결성 확보 가능</p></li>
</ul>
<p>즉, recipe를 이용해서 사전 정의된 object는 linear regression, random forest, xgboost 등등 tidymodel과 연동된 여러가지 모델에 대해 동일하게 적용할 수 있다. 또 recipe에는 생각보다 다양한 데이터 전처리 관련 함수가 있는데 이를 이용하면 기존에 각 변수별로 정의를 해주어야했던 데이터 전처리 과정을 간결하고 가독성 있는 코드로 구현이 가능하다.</p>
<p>세부적인 recipe 내에 step_fun은 다음과 같다.</p>
<ul>
<li><p>Normalization</p>
<div>
<ul>
<li>step_center(var) - 평균을 빼서 중심 이동</li>
<li>step_normalize(var) - 평균 빼고, 분산으로 나눠서 표준화</li>
</ul>
</div></li>
<li><p>Filters</p>
<div>
<ul>
<li><p>step_corr(threshold = 0.9) - 상관계수 절대값이 큰 변수 제거</p></li>
<li><p>step_rm(var) - 변수 제거</p></li>
<li><p>step_zv() - 분산이 0인 변수 제거</p></li>
<li><p>step_nzv() - 분산이 거의 0인 변수 제거</p></li>
</ul>
</div></li>
<li><p>Transformations</p>
<div>
<ul>
<li><p>step_log(var, base = exp(1) ) - 로그 변환</p></li>
<li><p>step_logit(var) - 로짓 변환</p></li>
<li><p>step_poly(var, degree = 2) - 변수에 polynomial term 추가(glm에서 poly() 와 동일, 즉 orthogonal polynomial 이용)</p></li>
<li><p>step_BoxCox() - Boxcox 변환</p></li>
<li><p>step_YeoJohnson - YeoJohnson 변환</p></li>
</ul>
</div></li>
<li><p>Discretization</p>
<div>
<ul>
<li><p>step_discretize(var, num_breaks = 4) - 연속형 변수 이산형으로 변환</p></li>
<li><p>step_cut() - 연속형 변수를 지정한 값을 기준으로 이산형으로 변환</p>
<div>
<ul>
<li><p>include_outside_range - 지정한 범위를 넘어선 값을 양끝 break에 포함시킬지 여부. default = FALSE이며 결측치 처리됨</p></li>
<li><p>breaks - 절단 기준이 되는 값</p></li>
</ul>
</div></li>
</ul>
</div></li>
<li><p>Dummy variables and encodings</p>
<div>
<ul>
<li><p>step_date() - date 변수에서 year, month, day of week 변수를 새롭게 생성</p>
<ul>
<li><p>feature = c(‘dow’, ‘month’, ‘year’) - 요일, 달, 연도 변수 추가</p></li>
<li><p>abbr = T - Sunday or Sun</p></li>
<li><p>label = Sunday or number</p></li>
</ul></li>
<li><p>step_holiday() - date 변수에서 공휴일에 관한 이진변수 새롭게 생성</p>
<div>
<ul>
<li><p>holidays = c(‘LaborDay’, ‘NewYearDay’, ‘ChristmasDay’)</p></li>
<li><p>holidays = timeDate::listHolidays(‘US’)</p></li>
</ul>
</div></li>
<li><p>step_dummy() - character or factor 변수를 더미변수로 변환</p>
<div>
<ul>
<li>one_hot = TRUE - C +1개의 더미변수 생성(one_hot = F: C-1개 더미변수 생성</li>
</ul>
</div></li>
<li><p>step_other() - 범주형 변수의 level이 여러개일 때, 하위 범주를 기타로 묶음</p>
<div>
<ul>
<li><p>threshold = 0.05 - 하위 5% 범주는 기타로 묶임</p></li>
<li><p>other : 기타로 지정할 level 이름 지정</p></li>
</ul>
</div></li>
<li><p>step_interact() - 상호작용 항 추가</p></li>
</ul>
</div></li>
</ul>
<pre class="r"><code>ames_rec &lt;- 
  recipe(sale_price ~ ., data = ames_train) %&gt;%
  step_string2factor(all_nominal()) %&gt;% 
  step_other(all_nominal(), threshold = 0.01) %&gt;%
  step_nzv(all_nominal())</code></pre>
</div>
<div id="prep" class="section level2">
<h2>Prep</h2>
<p>recipe object를 설정한 후에 prep을 이용해서 계산을 한다.</p>
<pre class="r"><code>ames_rec_prepped &lt;- prep(ames_rec)</code></pre>
</div>
<div id="bake" class="section level2">
<h2>Bake</h2>
<p>recipe, prep을 거쳐서 전처리된 데이터를 output으로 내보내는 단계이다.</p>
<p>데이터 전처리를 완료한 결과를 보고 싶으면 bake 함수를 이용하면 되는데 training data를 기준으로 이전에 데이터 전처리를 했기 때문에 <strong>new_data = training set을</strong> 넣고 중복 계산할 필요가 없다.</p>
<pre class="r"><code>ames_train_prepped &lt;- bake(ames_rec_prepped, new_data = NULL)</code></pre>
<p>test 데이터를 기준으로 전처리를 진행할 때 <strong>new_data = test set</strong>을 넣어주기만 하면 recipe, prep을 재지정해줄 필요 없이 곧바로 데이터 전처리가 가능하다.</p>
<pre class="r"><code>ames_test_prepped &lt;- bake(ames_rec_prepped, ames_test)</code></pre>
</div>
</div>
<div id="workflow" class="section level1">
<h1>Workflow</h1>
<p>워크플로우는 recipe, prep, bake를 이용해서 생성된 데이터를 이용해서 모델을 피팅하는 일련의 과정을 생성하는 것이다. 워크플로우의 플로우에 익숙해지면 가독성있게 코드 구현이 가능하며, tidymodels에서 제공하는 여러가지 모형을 간편하게 사용할 수 있다.</p>
<p>tidymodels에서는 워크플로우에 세팅할 수 있는 다양한 모형을 제공한다. 대표적으로 glm, random forest, XGboost Lightgbm, knn 등이 있으며, 모델을 튜닝하는 방식도 기본적인 gridsearch부터 bayes tuning까지 전부 지원한다.</p>
<p>예시로 간단하게 LASSO 모델을 구축해보겠다.</p>
<p>먼저 모형을 세팅하는 단계이다. tidymodels에는 LASSO가 사전에 구현되어있기 때문에 튜닝하고 싶은 파라미터만 정하면 된다. mixture = 1은 LASSO, mixture = 0은 ridge이며, mixture 까지 튜닝 파라미터로 넣으면 엘라스틱넷 모형이 된다.</p>
<pre class="r"><code>lasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% # mixture = 1 : LASSO, 0 : ridge 
  set_engine(&quot;glmnet&quot;)</code></pre>
<p>다음으로 세팅한 모델을 워크플로우에 태우는 단계이다. <strong>workflow()</strong>를 불러오고 <strong>add_formula()</strong> 를 이용해서 모델의 formula를 지정해준다. 마지막으로 이전에 세팅했던 LASSO 모델을 <strong>add_model()</strong> 을 이용해서 워크플로우에 태워준다.</p>
<pre class="r"><code>lasso_wf &lt;- workflow() %&gt;% 
    add_formula(sale_price ~.) %&gt;% 
    add_model(lasso_spec)
lasso_wf</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Formula
## Model: linear_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## sale_price ~ .
## 
## -- Model -----------------------------------------------------------------------
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet</code></pre>
<p><strong>add_formula()</strong>를 이용해서 formula를 지정할 수도 있지만 <strong>add_recipe()</strong>를 이용해서 워크플로우에 세팅할 수도 있다. <strong>add_recipe()</strong>에는 formula가 지정되어 있기 때문에 <strong>add_formula()</strong>로 중복지정해주면 에러가 난다. 만약에 formula를 재지정해주고 싶으면 <strong>remove_formula()</strong> 를 이용해서 formula를 제거하고 재지정해주면 된다.</p>
<pre class="r"><code>lasso_wf1 &lt;- workflow() %&gt;% 
  add_recipe(ames_rec) %&gt;%
  add_model(lasso_spec)</code></pre>
<p>다음으로는 모델 튜닝 방식을 정하는 단계이다. tidymodels에는 다양한 하이퍼파라미터 튜닝 방식이 존재한다. 대표적으로 grid_regular(), grid_latine_hypercube(), grid_max_entropy 등이 있다. LASSO는 튜닝 파라미터가 1개이므로 grid_regular()를 이용해서 튜닝을 해보도록 하겠다. levels는 튜닝 파라미터 후보군의 개수를 지정해주는 옵션이다.</p>
<pre class="r"><code>lambda_grid &lt;- grid_regular(penalty(), levels = 50)</code></pre>
<p>다음으로 모델 튜닝에 필요한 교차검증 데이터를 생성하는 단계이다. 교차검증 데이터셋은 <strong>vfold_cv()</strong>를 이용해서 구축할 수 있다.</p>
<pre class="r"><code>vb_folds &lt;- vfold_cv(ames_train_prepped, v = 5)
vb_folds</code></pre>
<pre><code>## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits             id   
##   &lt;list&gt;             &lt;chr&gt;
## 1 &lt;split [1876/470]&gt; Fold1
## 2 &lt;split [1877/469]&gt; Fold2
## 3 &lt;split [1877/469]&gt; Fold3
## 4 &lt;split [1877/469]&gt; Fold4
## 5 &lt;split [1877/469]&gt; Fold5</code></pre>
<p>다음으로 실제로 튜닝을 진행하는 단계이다. tidymodels는 모델을 튜닝할 때 계산속도 향상을 위해서 병렬처리 옵션을 지원한다. doParallel::registerDoParallel()을 지정해주면 코어 수에 맞게 병렬처리를 해준다.</p>
<p><strong>tune_grid()는</strong> 하이퍼파라미터 튜닝을 수행하는 함수이다. <strong>tune_grid()</strong>에는 워크플로우(lasso_wf), 교차검증셋(vb_folds), 튜닝 방식(lambda_grid)이 지정되어야한다. control 옵션은 최종 모델 피팅 후에 pred 값을 저장해주는 옵션이다. 옵션을 지정해놓으면 모델 피팅 후에 ROC plot을 그리거나 다른 기타 그래프로 그리는데 사용할 수 있다.</p>
<pre class="r"><code>lasso_res &lt;- tune_grid(
    lasso_wf, 
    resamples = vb_folds, 
    grid = lambda_grid, 
    control = control_grid(save_pred = TRUE), 
)</code></pre>
<p><strong>show_best()</strong> 를 이용해서 rmse 기준 best parameter를 볼 수 있다.</p>
<pre class="r"><code>show_best(lasso_res, &#39;rmse&#39;)</code></pre>
<pre><code>## # A tibble: 5 x 7
##    penalty .metric .estimator   mean     n std_err .config              
##      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
## 1 1.00e-10 rmse    standard   34207.     5   3331. Preprocessor1_Model01
## 2 1.60e-10 rmse    standard   34207.     5   3331. Preprocessor1_Model02
## 3 2.56e-10 rmse    standard   34207.     5   3331. Preprocessor1_Model03
## 4 4.09e-10 rmse    standard   34207.     5   3331. Preprocessor1_Model04
## 5 6.55e-10 rmse    standard   34207.     5   3331. Preprocessor1_Model05</code></pre>
<p>penalty parameter에 따라 rmse 값이 어떻게 바뀌는지 ggplot을 이용해서 그래프를 그릴 수 있다.</p>
<pre class="r"><code>lasso_res %&gt;% 
    collect_metrics() %&gt;% 
    ggplot(aes(penalty, mean, color = .metric)) + # .metric : rmse 
    geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err), alpha = 0.5) + 
    geom_line(size = 1.5, show.legend = F) + 
    facet_wrap(~.metric, scales = &#39;free&#39;, nrow = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>튜닝이 끝난 best parameter를 <strong>finalize_workflow()</strong> 를 이용해서 workflow에 업데이트한다.</p>
<pre class="r"><code>best_param &lt;- select_best(lasso_res, &#39;rmse&#39;)
final_lasso &lt;- finalize_workflow(lasso_wf, best_param)
final_lasso</code></pre>
<pre><code>## == Workflow ====================================================================
## Preprocessor: Formula
## Model: linear_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## sale_price ~ .
## 
## -- Model -----------------------------------------------------------------------
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 1e-10
##   mixture = 1
## 
## Computational engine: glmnet</code></pre>
<p>최종 모형을 train set에 적합시킨다.</p>
<pre class="r"><code>lasso_fit &lt;- fit(final_lasso, data = ames_train_prepped)</code></pre>
<p>마지막으로 test set에 모형을 적합시켜서 결과를 확인한다.</p>
<pre class="r"><code>pred_lasso &lt;- 
    predict(lasso_fit, ames_test_prepped) %&gt;% 
    mutate(modelo = &quot;LASSO&quot;)

pred_lasso %&gt;% head()</code></pre>
<pre><code>## # A tibble: 6 x 2
##     .pred modelo
##     &lt;dbl&gt; &lt;chr&gt; 
## 1  33290. LASSO 
## 2 259534. LASSO 
## 3 213952. LASSO 
## 4 198485. LASSO 
## 5 133947. LASSO 
## 6 304533. LASSO</code></pre>
<div id="참고-문헌" class="section level2">
<h2>참고 문헌</h2>
<p><a href="https://www.tmwr.org/ames.html">tidymodel with R bookdown</a></p>
<p><a href="https://recipes.tidymodels.org/reference/index.html">tidymodel recipe object</a></p>
<p><a href="%5Btidymodel%20recipe%20object%5D(https://recipes.tidymodels.org/reference/index.html)">How are categorical predictors handled in recipes?</a></p>
</div>
</div>
